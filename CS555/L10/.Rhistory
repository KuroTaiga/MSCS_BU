install.packages(c("rmarkdown", "knitr"))
#install.packages("asbio")
# https://cran.r-project.org/web/packages/asbio/index.html
library(asbio)
#Compute z*
ConfLevel <- 0.99 #Define confidence level
LeftTail <- ConfLevel+(1-ConfLevel)/2
zStar <- qnorm(LeftTail)
rnorm(100,mean = 114, sd = 514)
rnorm(100,mean = 114, sd = i)
rnorm(100,mean = 114, sd = -1)
rnorm(100,mean = 114, sd = 514)
quantile(rnorm(100,mean = 114, sd = 514))
mean(rnorm(100,114,514))
mean(rnorm(100,1,10000))
mean(rnorm(100,1,10000))
mean(rnorm(100,1,10000))
mean(rnorm(100,1,10000))
sd(rnorm(100,1,100))
sd(rnorm(100,1,10000))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
sd(rnorm(100,114,514))
#Compute z*
ConfLevel <- 0.99 #Define confidence level
LeftTail <- ConfLevel+(1-ConfLevel)/2
zStar <- qnorm(LeftTail)
dim()
a <- rnorm(rnorm(100,114,514) )
b <- sample(a, 49)
mean(b)
mean(a)
a <- rnorm(100,114,514)
b <- sample(a, 49)
mean(b)
mean(a)
b <- sample(a, 64)
mean(a)
mean(b)
3.6/6
3.5/6
2.576*3.5/6
92.83735-1.96*(sd(b)/8)
sd(b)
sd(a)
92.83735-1.96*(sd(a)/8)
1.96*sd(a)/8
a<-rnorm(100,10,10)
b<-sample(a,36)
sd(a)
sd(b)
mean(b)+1.96*10/8
mean(b)-1.96*10/8
mea(a)
mean(a)
mean(b)-1.645*10/8
mean(b)+1.645*10/8
qnorm(.1,lower.tail = F)
mean(b)-1.28*10/8
mean(b)+1.28*10/8
qnorm(.25,lower.tail = F)
(15/1*1.96)^2
ceiling((15/1*1.96)^2)
?one.sample.z
sd(a)
SD<-sd(a)
b <- sample(a,36)
mean(b)
bmean <- mean(b)
bmean <- 11
se = SD/6
critZ <- (mean(b)-bmean)/se
critZ <- (mean(b)-20)/se
one.sample.z(null.mu = 0, xbar = -2.98, sigma = 6, n=30,alternative = "one.sided")
one.sample.z(null.mu = 0, xbar = -2.98, sigma = 6, n=30,alternative = "less")
one.sample.z(null.mu = 155, xbar = 117, sigma = 30, n=100,alternative = "two.sided")
one.sample.z(null.mu = 115, xbar = 117, sigma = 30, n=100,alternative = "two.sided")
##Critical value approach
1.5967 > qnorm(0.975)
##P value approach
##replicate p value
pnorm(1.597, lower.tail = F)*2
##compare p value with alpha level
0.11 < 0.05
help("fit")
??fit
library(python)
install.packages("reticulate")
one.sample.z(null.mu = 42, xbar = 38.37524, sigma = 23.74226, n=36,alternative = "two.sided")
one.sample.z(null.mu = 42, xbar = 38.37524, sigma = 23.74226, n=36,alternative = "two.si")
one.sample.z(null.mu = 42, xbar = 38.37524, sigma = 23.74226, n=36,alternative = "less")
sigma <- 169
(xbar <- mean(sample))
(z <- qnorm(0.975))
(cl <- c(xbar-z*sigma/sqrt(40), xbar+z*sigma/sqrt(40)))
one.sample.z(null.mu=919, xbar=xbar, sigma=169,
n=40, alternative="two.sided", conf=0.95)
z <- qnorm(0.975)
sigma <- 4
m <- 0.5
n <- (z*sigma/m)^2
n
one.sample.z(null.mu=10, xbar=10.8, sigma=1,
n=30, alternative="greater", conf=0.95)
one.sample.z(null.mu=10, xbar=10.8, sigma=1,
n=30, alternative="greater")
zval <- (16.4-15)/(6.2/sqrt(50))
(zval <- (16.4-15)/(6.2/sqrt(50)))
##Critical value approach
1.5967 > qnorm(0.975)
kid_cal <- read.csv("kid_cal.csv")
summary(kid_cal)
Kid_mean <- kid_cal$trt
Kid_meal <- kid_cal$trt = T
kid_cal <- read.csv("kid_cal.csv")
Kid_meal <- kid_cal$trt = T
Kid_meal <- kid_cal[kid_cal$trt = T]
Kid_meal <- kid_cal[kid_cal$trt == T]
Kid_meal <- kid_cal$Calories[kid_cal$trt == T]
Kid_no_meal <- kid_cal$Calories[kid_cal$trt == F]
hist(Kid_meal)
par(mfrow = c(2,2))
hist(Kid_meal)
hist(Kid_no_meal)
knitr::opts_chunk$set(echo = TRUE)
hist(Kid_no_meal, main = "Calorie Distribution for Non-Participants",
xlab = "Calorie", freq = F)
hist(Kid_no_meal, main = "Calorie Distribution for Non-Participants",
xlab = "Calorie", ylab = "Child Count")
knitr::opts_chunk$set(echo = TRUE)
kid_cal <- read.csv("kid_cal.csv")
Kid_meal <- kid_cal$Calories[kid_cal$trt == T]
Kid_no_meal <- kid_cal$Calories[kid_cal$trt == F]
mealFrame <- data.frame(
Mean = mean(Kid_meal),
Median = median(Kid_meal),
SD = sd(Kid_meal),
First_Quantile = quantile(Kid_meal,.25)[[1]],
Third_Quantile = quantile(Kid_meal,.75)[[1]],
Min = min(Kid_meal),
Max = max(Kid_meal)
)
daysTable <- kable(mealFrame,"simple")
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
kid_cal <- read.csv("kid_cal.csv")
Kid_meal <- kid_cal$Calories[kid_cal$trt == T]
Kid_no_meal <- kid_cal$Calories[kid_cal$trt == F]
mealFrame <- data.frame(
Mean = mean(Kid_meal),
Median = median(Kid_meal),
SD = sd(Kid_meal),
First_Quantile = quantile(Kid_meal,.25)[[1]],
Third_Quantile = quantile(Kid_meal,.75)[[1]],
Min = min(Kid_meal),
Max = max(Kid_meal)
)
daysTable <- kable(mealFrame,"simple")
par(mfrow = c(2,2))
hist(Kid_meal, main = "Calorie Distribution for Participants",
xlab = "Calorie", ylab = "Child Count")
hist(Kid_no_meal, main = "Calorie Distribution for Non-Participants",
xlab = "Calorie", ylab = "Child Count")
(mealTable <- kable(mealFrame,"simple"))
(mealTable <- kable(mealFrame,"simple", label = "Summary of Calorie for Participants of Meal Preparation"))
setwd("C:/BU/CSSE/CS555/HW5/")
knitr::opts_chunk$set(echo = TRUE)
dataSet <- read.csv("./A05.csv")
summary(dataSet)
head(dataSet)
dataSet$group <- as.factor(dataSet$group)
summary(dataSet)
head(dataSet)
summary(dataSet)
summary(dataSet)
boxplot(data = dataSet)
attach(dataSet)
summary(dataSet)
boxplot(iq~group,data = dataSet)
boxplot(iq~group,data = dataSet, main="IQ test by Student Group", xlab="Student Group",
ylab="IQ Test Score")
boxplot(age~group,data = dataSet, main="Age by Student Group", xlab="Student Group",
ylab="Age")
qf(.95,2,42)
aov(iq~group,data = dataSet)
summary(aov(iq~group,data = dataSet))
585.9/22.1
TukeyHSD(m)
m <- aov(iq~group, data = dataSet)
TukeyHSD(m)
dataSet$g0 <- ifelse(group == 'Chemistry student', 1, 0)
dataSet$g1 <- ifelse(group=='Math student', 1, 0)
dataSet$g2 <- ifelse(group=='Physics student', 1, 0)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g0+g2,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g1+g0,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g0+g2,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g0+g1,data=dataSet)
anova(m1)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
setwd("C:/BU/CSSE/CS555/L10/")
# Golf ball travel distance example
golf <- read.csv("golfball_C.csv")
head(golf)
golf$brand <- as.factor(golf$brand)
summary(golf)
attach(golf)
## runing one-way anova using aov function
g <- aov(dist~brand, data=golf)
summary(g)
## pairwise t test to find which two
## are different
pairwise.t.test(dist, brand, p.adj='none')
pairwise.t.test(dist, brand, p.adj='bonferroni')
TukeyHSD(g)
##Define dummy variables
##g0 is Callaway
##g1 is Nike
##g2 is Titleist
golf$g0 <- ifelse(brand=='Callaway', 1, 0)
golf$g1 <- ifelse(brand=='Nike', 1, 0)
golf$g2 <- ifelse(brand=='Titleist', 1, 0)
##g0 is Callaway (Middle 285)
##g1 is Nike (Lowest 260)
##g2 is Titleist (Highest 290)
##g1 is the reference group
m1 <- lm(dist~g0+g2, data=golf)
anova(m1)
summary(m1)
summary(m1)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
summary(m1)
5090-150
4940/213
50/23.2
# Speed as the response
model1 <- lm(Speed~PreStretch+AnkleWeights
+PreStretch*AnkleWeights,
data=exercise)
summary(model1)
Anova(model1, type=3)
# ANCOVA
library(car)
#Least square means
# also called Estimated marginal means (EMMs)
# emmeans is the replacement for the lsmeans
# library, so if you see code referring to
# lsmeans, it is conceptually doing the same
# thing as what emmeans will do. emmeans is
# being developed; lsmeans is now deprecated.
install.packages("emmeans")
library(emmeans)
install.packages("lsmeans")
library(lsmeans)
####################
## Section 03
####################
# Exercise example
exercise <- read.csv("exercise.csv")
exercise
attach(exercise)
#Test interactions
# Energy as the response
model <- lm(Energy~PreStretch+AnkleWeights+
PreStretch*AnkleWeights,
data=exercise)
summary(model)
Anova(model, type=3)
# Speed as the response
model1 <- lm(Speed~PreStretch+AnkleWeights
+PreStretch*AnkleWeights,
data=exercise)
summary(model1)
Anova(model1, type=3)
# Oxygen as the response
model2 <- lm(Oxygen~PreStretch+AnkleWeights
+PreStretch*AnkleWeights,
data=exercise)
summary(model2)
Anova(model2, type=3)
# Generate interaction plots
interaction.plot(PreStretch, AnkleWeights,
Energy, col=1:2)
interaction.plot(PreStretch, AnkleWeights,
Speed, col=1:2)
interaction.plot(PreStretch, AnkleWeights,
Speed, col=1:2)
interaction.plot(PreStretch, AnkleWeights,
Oxygen, col=1:2)
interaction.plot(c(9.2,8.7),c(8.1,5.4))
Oxygen
PreStretch
interaction.plot(c(1,0,1,0),c(1,1,0,0),c(9.2,8.7,8.1,5.4))
#If interaction is significant, need to
# stratify (by one of the two factors)
# Since the interaction term is not significant,
# this is just for demo.
stretch <- exercise[which(PreStretch=='Stretch'),]
nostretch <- exercise[which(PreStretch=='No stretch'),]
summary(aov(Energy~AnkleWeights, data=stretch))
summary(aov(Energy~AnkleWeights, data=nostretch))
#Test interactions
# Energy as the response
model <- lm(Energy~PreStretch+AnkleWeights+
PreStretch*AnkleWeights,
data=exercise)
summary(model)
Anova(model, type=3)
# Speed as the response
model1 <- lm(Speed~PreStretch+AnkleWeights
+PreStretch*AnkleWeights,
data=exercise)
summary(model1)
Anova(model1, type=3)
Anova(lm(c(9.2,9.7,8.1,5.4)~c(1,1,0,0)+c(1,0,1,0)+c(1,1,0,0)*c(1,0,1,0)),type=3)
AnkleWeights
eightHours = c(1,0,1,0)
coffee = c(1,1,0,0)
outPut = c(9.2,8.7,8.1,5.4)
exercise
c(eightHours,coffee,outPut)
df(eightHours,coffee,outPut)
modelcoffee <- lm(outPut~coffee+eightHours+coffee*eightHours,data = )
modelcoffee
Anova(modelcoffee)
AnkleWeights <- coffee
PreStretch<-eightHours
Oxygen<-outPut
exercise
AnkleWeights
exercise <- exercise[:4]
exercise <- exercise[1,2,3,4]
data.frame(coffee,eightHours,outPut)
modelsleep <- lm(outPut~coffee+eightHours+coffee*eightHours,data = data.frame(coffee,eightHours,outPut))
Anova(modelsleep,type=3)
qf(0.00001,df1=2,df2=42)
qf(0.99999,df1=2,df2=42)
1-0.8^60
60*0.9999985
qf(0.95,df1=9,df2=235)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
summary(m1)
knitr::opts_chunk$set(echo = TRUE)
dataSet <- read.csv("./A05.csv")
dataSet$group <- as.factor(dataSet$group)
attach(dataSet)
summary(dataSet)
boxplot(iq~group,data = dataSet, main="IQ test by Student Group", xlab="Student Group",
ylab="IQ Test Score")
boxplot(age~group,data = dataSet, main="Age by Student Group", xlab="Student Group",
ylab="Age")
summary(aov(iq~group,data = dataSet))
m <- aov(iq~group, data = dataSet)
TukeyHSD(m)
dataSet$g0 <- ifelse(group == 'Chemistry student', 1, 0)
dataSet$g1 <- ifelse(group=='Math student', 1, 0)
dataSet$g2 <- ifelse(group=='Physics student', 1, 0)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
summary(m1)
m1 <- lm(iq ~ g0+g2,data=dataSet)
anova(m1)
summary(m1)
m1 <- lm(iq ~ g1+g2,data=dataSet)
anova(m1)
summary(m1)
summary(m1)
summary(anova(m1))
anova(m1)
summary(m1)
anova(m1)
summary(m1)
library(car)
m2<-lm(iq~group+age,data=dataSet)
Anova(m2,type=3)
## What do you find by adjusting for age?
Anova(lm(data$SBP~data$group+data$age, data=data), type=3)
####################
## Section 02
####################
### SBP by smoking status example
data <- read.csv("smoking_SBP.csv")
## What do you find by adjusting for age?
Anova(lm(data$SBP~data$group+data$age, data=data), type=3)
library(emmeans)
options('contrasts')
# contr.treatment is for non-ordered: eg. male vs female
#mostly we treat it as undered
#http://www.dummies.com/programming/r/how-to-set-the-contrasts-for-your-data-with-r/
X <- factor(c('A','B','C'))
contr.treatment(X)
options(contrasts=c("contr.treatment", "contr.poly"))
m6 <- lm(data$SBP~data$group+data$age,data=data)
(m6.rg1 <- ref.grid(m6)) ##rgl: reference group level
# The 2nd is the variable we want
# to work with. It must be one of the
# variables in the fitted model.
# The function produces a table with estimated
# means, standard errors and
# confidence intervals for each mean.
# To get something other than 95% confidence
# intervals, use
# summary( , level=0.90) to specify
# the coverage you want
(m6.emm <- emmeans(m6, 'group'))
summary(m6.emm, level=0.90)
(m2.emm <- emmeans(m2, 'group'))
library(emmeans)
