{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4bea2d-289b-4ae1-9b59-2807c0459fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19, ResNet50V2, InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "dataset = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "data = dataset['valid']\n",
    "\n",
    "# Adjust the image size and preprocessing function for each model\n",
    "image_sizes = {\n",
    "    'VGG19': (224, 224),\n",
    "    'ResNet50V2': (224, 224),\n",
    "    'InceptionV3': (299, 299) # Adjusting for InceptionV3 instead of V4\n",
    "}\n",
    "\n",
    "preprocessing_functions = {\n",
    "    'VGG19': tf.keras.applications.vgg19.preprocess_input,\n",
    "    'ResNet50V2': tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    'InceptionV3': tf.keras.applications.inception_v3.preprocess_input\n",
    "}\n",
    "\n",
    "# Load the pre-trained models\n",
    "vgg19 = VGG19(weights='imagenet')\n",
    "resnet50v2 = ResNet50V2(weights='imagenet')\n",
    "inceptionv3 = InceptionV3(weights='imagenet')  # Proxy for InceptionV4\n",
    "\n",
    "vgg19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "resnet50v2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "inceptionv3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7265f65c-1b9f-400d-b83a-be6a38cbe863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, model_name):\n",
    "    \"\"\"Preprocess images to the required size and format for a given model.\"\"\"\n",
    "    new_data = data\n",
    "    for i in range(len(new_data['image'])):\n",
    "   \n",
    "        img = new_data['image'][i]\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "        preprocess_function = preprocessing_functions[model_name]\n",
    "        img_preprocessed = preprocess_function(img_array_expanded)\n",
    "        new_data['image'][i] = img_preprocessed\n",
    "    print(\"done!\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f67729-9038-463d-8efb-84165642979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vgg19 = preprocess_dataset(data, 'VGG19')\n",
    "#dataset_resnet = preprocess_dataset(data, 'ResNet50V2')\n",
    "#dataset_inception = preprocess_dataset(data, 'InceptionV3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64063c25-4c6c-4e35-b8e8-e03cd496000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=Dataset({\n    features: ['image', 'label'],\n    num_rows: 10000\n}) (of type <class 'datasets.arrow_dataset.Dataset'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG19\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m vgg19\u001b[38;5;241m.\u001b[39mevaluate(dataset_vgg19)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:113\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x=Dataset({\n    features: ['image', 'label'],\n    num_rows: 10000\n}) (of type <class 'datasets.arrow_dataset.Dataset'>)"
     ]
    }
   ],
   "source": [
    "print(\"VGG19\")\n",
    "loss, accuracy = vgg19.evaluate(dataset_vgg19)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc679de-acb8-4b41-bbcb-484db8906df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ResNet50\")\n",
    "loss, accuracy = resnet50v2.evaluate(dataset_resnet)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdce662-17d0-4c81-b460-4b659b4753f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"InceptionV3\")\n",
    "loss, accuracy = inceptionv3.evaluate(dataset_inception)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
