{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f325b1-cdf4-4e5d-94e9-ee4275091ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data','tiny-imagenet-200.zip')):\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','tiny-imagenet-200.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'tiny-imagenet-200')):\n",
    "    with zipfile.ZipFile(os.path.join('data','tiny-imagenet-200.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45be974c-80fa-42a8-a9ed-486c7fd29068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed = 1997\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89d48f2b-c04c-43b0-85ed-160f59f34d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n",
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_test_labels_df(test_labels_path):\n",
    "    \"\"\" Reading the test data labels for all files in the test set as a data frame \"\"\"\n",
    "    test_df = pd.read_csv(test_labels_path, sep='\\t', index_col=None, header=None)\n",
    "    test_df = test_df.iloc[:,[0,1]].rename({0:\"filename\", 1:\"class\"}, axis=1)\n",
    "    return test_df\n",
    "\n",
    "def get_train_valid_test_data_generators(batch_size, target_size):\n",
    "    \"\"\" Get the training/validation/testing data generators \"\"\"\n",
    "    \n",
    "    # Defining a data-augmenting image data generator and a standard image data generator\n",
    "    image_gen_aug = ImageDataGenerator(\n",
    "        samplewise_center=False, rotation_range=30, width_shift_range=0.2,\n",
    "        height_shift_range=0.2, brightness_range=(0.5,1.5), shear_range=5, \n",
    "        zoom_range=0.2, horizontal_flip=True, fill_mode='constant', cval=127.5, \n",
    "        validation_split=0.1\n",
    "    )\n",
    "    image_gen = ImageDataGenerator(samplewise_center=False)\n",
    "    \n",
    "    # Define a training data generator\n",
    "    partial_flow_func = partial(\n",
    "        image_gen_aug.flow_from_directory, \n",
    "        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n",
    "        target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, \n",
    "        shuffle=True, seed=random_seed)\n",
    "    \n",
    "    # Get the training data subset\n",
    "    train_gen = partial_flow_func(subset='training')\n",
    "    # Get the validation data subset\n",
    "    valid_gen = partial_flow_func(subset='validation')    \n",
    "\n",
    "    # Defining the test data generator\n",
    "    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  'val', 'val_annotations.txt'))\n",
    "    test_gen = image_gen.flow_from_dataframe(\n",
    "        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "\n",
    "batch_size = 48\n",
    "target_size = (224,224)\n",
    "# Getting the train,valid, test data generators\n",
    "train_gen, valid_gen, test_gen = get_train_valid_test_data_generators(batch_size, target_size)\n",
    "# Modifying the data generators to fit the model targets\n",
    "train_gen_inceptionV3, valid_gen_inceptionV3, test_gen_inceptionV3 = get_train_valid_test_data_generators(batch_size,(299,299))\n",
    "\n",
    "with open(os.path.join('data','class_indices'), 'wb') as f:\n",
    "    pickle.dump(train_gen.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7466a4-7a05-4e71-bdb4-dcb1ab0f79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19,ResNet50V2,InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "def create_inceptionv3_model(input_shape=(299, 299, 3), num_classes=200):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "inceptionv3_model = create_inceptionv3_model()\n",
    "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_resnet50v2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet50v2_model = create_resnet50v2_model()\n",
    "resnet50v2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg19_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg19_model = create_vgg19_model()\n",
    "vgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg19_model.summary()\n",
    "#resnet50v2_model.summary()\n",
    "#inceptionv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36e42e39-445d-40c3-8786-1171b027b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2398s\u001b[0m 1s/step - accuracy: 0.1344 - loss: 71.9380 - val_accuracy: 0.1792 - val_loss: 87.6753 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\docto\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2401s\u001b[0m 1s/step - accuracy: 0.2048 - loss: 84.7710 - val_accuracy: 0.1995 - val_loss: 98.3656 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2327s\u001b[0m 1s/step - accuracy: 0.2261 - loss: 91.3884 - val_accuracy: 0.2150 - val_loss: 105.6772 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2447 - loss: 95.4093\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2348s\u001b[0m 1s/step - accuracy: 0.2447 - loss: 95.4108 - val_accuracy: 0.2223 - val_loss: 109.1087 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2349s\u001b[0m 1s/step - accuracy: 0.2854 - loss: 83.1943 - val_accuracy: 0.2564 - val_loss: 86.6057 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 433ms/step - accuracy: 0.2683 - loss: 104.4380\n",
      "{'loss': 103.57467651367188, 'compile_metrics': 0.26840001344680786}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=25)\n",
    "lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n",
    ")\n",
    "def get_steps_per_epoch(n_data, batch_size):\n",
    "    \"\"\" Given the data size and batch size, gives the number of steps to travers the full dataset \"\"\"\n",
    "    if n_data%batch_size==0:\n",
    "        return int(n_data/batch_size)\n",
    "    else:\n",
    "        return int(n_data*1.0/batch_size)+1\n",
    "\n",
    "n_epochs=10\n",
    "history = vgg19_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "vgg19_model.save(os.path.join('models', 'VGG19.h5'))\n",
    "\n",
    "# Evaluate the model\n",
    "test_res = vgg19_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d82bfb2c-5132-48ce-853f-be2d996348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1153s\u001b[0m 614ms/step - accuracy: 0.0844 - loss: 11.0608 - val_accuracy: 0.0760 - val_loss: 11.3525 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1151s\u001b[0m 613ms/step - accuracy: 0.0822 - loss: 10.7372 - val_accuracy: 0.0695 - val_loss: 10.8958 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1153s\u001b[0m 614ms/step - accuracy: 0.0786 - loss: 10.4283 - val_accuracy: 0.0716 - val_loss: 10.6036 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.0804 - loss: 10.1156\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1154s\u001b[0m 615ms/step - accuracy: 0.0804 - loss: 10.1155 - val_accuracy: 0.0673 - val_loss: 10.3167 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 614ms/step - accuracy: 0.1021 - loss: 7.5484 - val_accuracy: 0.0909 - val_loss: 7.6646 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "n_epochs=10\n",
    "history = resnet50v2_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "resnet50v2_model.save(os.path.join('models', 'RESNET50.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f5c9ee3-e2bc-4409-a848-cc01bf1d50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 190ms/step - accuracy: 0.1102 - loss: 9.2185 \n",
      "{'loss': 9.21091079711914, 'compile_metrics': 0.11180000007152557}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = resnet50v2_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6675129a-1500-4443-9d6b-3f6757c531ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 835ms/step - accuracy: 0.0569 - loss: 6.3051 - val_accuracy: 0.0479 - val_loss: 6.4472 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1572s\u001b[0m 837ms/step - accuracy: 0.0568 - loss: 6.1339 - val_accuracy: 0.0524 - val_loss: 6.2429 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 835ms/step - accuracy: 0.0554 - loss: 6.0417 - val_accuracy: 0.0510 - val_loss: 6.1951 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.0557 - loss: 5.9627\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1572s\u001b[0m 837ms/step - accuracy: 0.0557 - loss: 5.9627 - val_accuracy: 0.0492 - val_loss: 6.0624 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 835ms/step - accuracy: 0.0691 - loss: 5.2584 - val_accuracy: 0.0636 - val_loss: 5.3561 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "n_epochs=10\n",
    "history = inceptionv3_model.fit(\n",
    "    train_gen_inceptionV3, validation_data=valid_gen_inceptionV3, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback])\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "inceptionv3_model.save(os.path.join('models', 'InceptionV3.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0813cd3c-1c28-45e4-b99e-c9088fde7033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 214ms/step - accuracy: 0.0800 - loss: 5.3361\n",
      "{'loss': 5.319585800170898, 'compile_metrics': 0.08060000091791153}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = inceptionv3_model.evaluate(test_gen_inceptionV3, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
