{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f325b1-cdf4-4e5d-94e9-ee4275091ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data','tiny-imagenet-200.zip')):\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','tiny-imagenet-200.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'tiny-imagenet-200')):\n",
    "    with zipfile.ZipFile(os.path.join('data','tiny-imagenet-200.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45be974c-80fa-42a8-a9ed-486c7fd29068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed = 1997\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a913a6dd-4785-4ed7-9317-47df3b6e141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10.0\n",
      "  Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\docto\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.10.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (23.2)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl.metadata (806 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.62.1)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
      "Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: keras, tensorboard-data-server, protobuf, tensorboard, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.1.1\n",
      "    Uninstalling keras-3.1.1:\n",
      "      Successfully uninstalled keras-3.1.1\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed keras-2.10.0 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-datasets 4.9.4 requires tqdm, which is not installed.\n",
      "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d48f2b-c04c-43b0-85ed-160f59f34d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n",
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_test_labels_df(test_labels_path):\n",
    "    \"\"\" Reading the test data labels for all files in the test set as a data frame \"\"\"\n",
    "    test_df = pd.read_csv(test_labels_path, sep='\\t', index_col=None, header=None)\n",
    "    test_df = test_df.iloc[:,[0,1]].rename({0:\"filename\", 1:\"class\"}, axis=1)\n",
    "    return test_df\n",
    "\n",
    "def get_train_valid_test_data_generators(batch_size, target_size):\n",
    "    \"\"\" Get the training/validation/testing data generators \"\"\"\n",
    "    \n",
    "    # Defining a data-augmenting image data generator and a standard image data generator\n",
    "    image_gen_aug = ImageDataGenerator(\n",
    "        samplewise_center=False, rotation_range=30, width_shift_range=0.2,\n",
    "        height_shift_range=0.2, brightness_range=(0.5,1.5), shear_range=5, \n",
    "        zoom_range=0.2, horizontal_flip=True, fill_mode='constant', cval=127.5, \n",
    "        validation_split=0.1\n",
    "    )\n",
    "    image_gen = ImageDataGenerator(samplewise_center=False)\n",
    "    \n",
    "    # Define a training data generator\n",
    "    partial_flow_func = partial(\n",
    "        image_gen_aug.flow_from_directory, \n",
    "        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n",
    "        target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, \n",
    "        shuffle=True, seed=random_seed)\n",
    "    \n",
    "    # Get the training data subset\n",
    "    train_gen = partial_flow_func(subset='training')\n",
    "    # Get the validation data subset\n",
    "    valid_gen = partial_flow_func(subset='validation')    \n",
    "\n",
    "    # Defining the test data generator\n",
    "    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  'val', 'val_annotations.txt'))\n",
    "    test_gen = image_gen.flow_from_dataframe(\n",
    "        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "\n",
    "batch_size = 48\n",
    "target_size = (224,224)\n",
    "# Getting the train,valid, test data generators\n",
    "train_gen, valid_gen, test_gen = get_train_valid_test_data_generators(batch_size, target_size)\n",
    "# Modifying the data generators to fit the model targets\n",
    "train_gen_inceptionV3, valid_gen_inceptionV3, test_gen_inceptionV3 = get_train_valid_test_data_generators(batch_size,(299,299))\n",
    "\n",
    "with open(os.path.join('data','class_indices'), 'wb') as f:\n",
    "    pickle.dump(train_gen.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7466a4-7a05-4e71-bdb4-dcb1ab0f79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19,ResNet50V2,InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "def create_inceptionv3_model(input_shape=(299, 299, 3), num_classes=200):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "inceptionv3_model = create_inceptionv3_model()\n",
    "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_resnet50v2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet50v2_model = create_resnet50v2_model()\n",
    "resnet50v2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg19_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg19_model = create_vgg19_model()\n",
    "vgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg19_model.summary()\n",
    "#resnet50v2_model.summary()\n",
    "#inceptionv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa9a727-56e5-462a-a2a3-352af3aeb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=25)\n",
    "lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n",
    ")\n",
    "def get_steps_per_epoch(n_data, batch_size):\n",
    "    \"\"\" Given the data size and batch size, gives the number of steps to travers the full dataset \"\"\"\n",
    "    if n_data%batch_size==0:\n",
    "        return int(n_data/batch_size)\n",
    "    else:\n",
    "        return int(n_data*1.0/batch_size)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179bf772-6b5d-42e4-8467-e2b03150eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 437s 230ms/step - loss: 73.8320 - accuracy: 0.1364 - val_loss: 84.5855 - val_accuracy: 0.1780 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 87.3286 - accuracy: 0.2016 - val_loss: 96.6730 - val_accuracy: 0.2017 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 93.7164 - accuracy: 0.2270 - val_loss: 104.8548 - val_accuracy: 0.2191 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 97.4487 - accuracy: 0.2436 - val_loss: 108.5414 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 100.7292 - accuracy: 0.2532 - val_loss: 113.6165 - val_accuracy: 0.2301 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 102.9009 - accuracy: 0.2622\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 102.9009 - accuracy: 0.2622 - val_loss: 118.0585 - val_accuracy: 0.2331 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 453s 242ms/step - loss: 83.4226 - accuracy: 0.3100 - val_loss: 95.3592 - val_accuracy: 0.2741 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 75.8246 - accuracy: 0.3265 - val_loss: 91.1789 - val_accuracy: 0.2810 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 71.6984 - accuracy: 0.3329 - val_loss: 87.5145 - val_accuracy: 0.2793 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 68.5497 - accuracy: 0.3398 - val_loss: 84.4488 - val_accuracy: 0.2834 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 65.8935 - accuracy: 0.3440 - val_loss: 81.7813 - val_accuracy: 0.2865 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 63.3783 - accuracy: 0.3495 - val_loss: 80.3479 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 61.9323 - accuracy: 0.3516 - val_loss: 76.7771 - val_accuracy: 0.2938 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 60.0185 - accuracy: 0.3519 - val_loss: 76.7582 - val_accuracy: 0.2874 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 58.1976 - accuracy: 0.3547 - val_loss: 74.2841 - val_accuracy: 0.2948 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 56.8493 - accuracy: 0.3555 - val_loss: 71.9456 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 55.5574 - accuracy: 0.3565 - val_loss: 73.6436 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 54.2527 - accuracy: 0.3609 - val_loss: 71.6941 - val_accuracy: 0.2900 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 53.3031 - accuracy: 0.3618 - val_loss: 70.0027 - val_accuracy: 0.2955 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 52.4658 - accuracy: 0.3602 - val_loss: 68.6842 - val_accuracy: 0.2927 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 50.8566 - accuracy: 0.3667 - val_loss: 67.4520 - val_accuracy: 0.2928 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 50.3913 - accuracy: 0.3645 - val_loss: 66.7736 - val_accuracy: 0.2914 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 49.3019 - accuracy: 0.3668 - val_loss: 66.1333 - val_accuracy: 0.2925 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 48.4147 - accuracy: 0.3673 - val_loss: 64.9001 - val_accuracy: 0.2950 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 47.4963 - accuracy: 0.3686 - val_loss: 63.8421 - val_accuracy: 0.2953 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 47.0168 - accuracy: 0.3696 - val_loss: 63.1961 - val_accuracy: 0.3016 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 46.0692 - accuracy: 0.3698 - val_loss: 62.8753 - val_accuracy: 0.2938 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 45.5665 - accuracy: 0.3720 - val_loss: 62.7460 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 44.7027 - accuracy: 0.3724 - val_loss: 60.3570 - val_accuracy: 0.2937 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 44.1026 - accuracy: 0.3715 - val_loss: 60.4472 - val_accuracy: 0.2968 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 43.3765 - accuracy: 0.3746 - val_loss: 59.8975 - val_accuracy: 0.2903 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 42.8766 - accuracy: 0.3759 - val_loss: 58.5216 - val_accuracy: 0.2936 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 42.3922 - accuracy: 0.3751 - val_loss: 58.3608 - val_accuracy: 0.2954 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 41.9932 - accuracy: 0.3749 - val_loss: 58.1317 - val_accuracy: 0.2926 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 41.1064 - accuracy: 0.3773 - val_loss: 57.2087 - val_accuracy: 0.2993 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 40.7336 - accuracy: 0.3770 - val_loss: 56.2209 - val_accuracy: 0.2948 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 40.4248 - accuracy: 0.3771 - val_loss: 55.9744 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 440s 235ms/step - loss: 39.6314 - accuracy: 0.3787 - val_loss: 55.6802 - val_accuracy: 0.3023 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 39.2698 - accuracy: 0.3784 - val_loss: 55.3899 - val_accuracy: 0.2936 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 38.7091 - accuracy: 0.3786 - val_loss: 55.1386 - val_accuracy: 0.2944 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 38.3287 - accuracy: 0.3812 - val_loss: 53.4432 - val_accuracy: 0.3005 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 37.8199 - accuracy: 0.3822 - val_loss: 53.4589 - val_accuracy: 0.2931 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 37.3281 - accuracy: 0.3838 - val_loss: 53.2803 - val_accuracy: 0.2980 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 37.1303 - accuracy: 0.3821 - val_loss: 52.6261 - val_accuracy: 0.2907 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 36.6186 - accuracy: 0.3809 - val_loss: 52.7623 - val_accuracy: 0.2988 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 438s 234ms/step - loss: 36.1626 - accuracy: 0.3830 - val_loss: 52.1278 - val_accuracy: 0.2883 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 35.8713 - accuracy: 0.3825 - val_loss: 51.0938 - val_accuracy: 0.2971 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 35.3559 - accuracy: 0.3825 - val_loss: 51.5518 - val_accuracy: 0.2940 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 35.1754 - accuracy: 0.3831 - val_loss: 50.6364 - val_accuracy: 0.2920 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 34.9892 - accuracy: 0.3845 - val_loss: 50.3060 - val_accuracy: 0.2967 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = vgg19_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "vgg19_model.save(os.path.join('models', 'VGG19_30epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084c1084-29ae-4cbd-a657-46d31ad958ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 32s - loss: 62.8520 - accuracy: 0.3066WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 22s 43ms/step - loss: 62.8535 - accuracy: 0.3064\n",
      "{'loss': 62.85350036621094, 'accuracy': 0.30640000104904175}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = vgg19_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(vgg19_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d82bfb2c-5132-48ce-853f-be2d996348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 433s 230ms/step - loss: 64.6342 - accuracy: 0.0218 - val_loss: 61.0181 - val_accuracy: 0.0270 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 62.2299 - accuracy: 0.0304 - val_loss: 58.3081 - val_accuracy: 0.0319 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 61.2347 - accuracy: 0.0357 - val_loss: 58.4649 - val_accuracy: 0.0446 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 60.4660 - accuracy: 0.0382 - val_loss: 55.1613 - val_accuracy: 0.0398 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 60.5263 - accuracy: 0.0407 - val_loss: 70.9044 - val_accuracy: 0.0347 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 60.1795 - accuracy: 0.0417 - val_loss: 56.4137 - val_accuracy: 0.0432 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 58.8732 - accuracy: 0.0426 - val_loss: 55.3189 - val_accuracy: 0.0454 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 59.6477 - accuracy: 0.0453 - val_loss: 60.3410 - val_accuracy: 0.0465 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 58.0646 - accuracy: 0.0461 - val_loss: 54.2681 - val_accuracy: 0.0506 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 58.8614 - accuracy: 0.0473 - val_loss: 58.2778 - val_accuracy: 0.0443 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 58.3930 - accuracy: 0.0478 - val_loss: 55.3911 - val_accuracy: 0.0472 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 57.2473 - accuracy: 0.0494 - val_loss: 55.6855 - val_accuracy: 0.0421 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 58.0823 - accuracy: 0.0502 - val_loss: 59.6118 - val_accuracy: 0.0431 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 57.9131 - accuracy: 0.0505\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 438s 234ms/step - loss: 57.9131 - accuracy: 0.0505 - val_loss: 65.2486 - val_accuracy: 0.0593 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 13.3814 - accuracy: 0.1136 - val_loss: 11.9698 - val_accuracy: 0.1025 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 10.8401 - accuracy: 0.1131 - val_loss: 11.9179 - val_accuracy: 0.0948 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 10.5469 - accuracy: 0.1097 - val_loss: 11.3938 - val_accuracy: 0.0949 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 10.2307 - accuracy: 0.1086 - val_loss: 10.9398 - val_accuracy: 0.0920 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 10.0183 - accuracy: 0.1055 - val_loss: 10.8854 - val_accuracy: 0.0900 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 9.8491 - accuracy: 0.1063 - val_loss: 10.1321 - val_accuracy: 0.0972 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 9.6378 - accuracy: 0.1064 - val_loss: 10.0964 - val_accuracy: 0.1019 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 9.5248 - accuracy: 0.1061 - val_loss: 9.8412 - val_accuracy: 0.0973 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 9.3896 - accuracy: 0.1059 - val_loss: 10.0998 - val_accuracy: 0.0985 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 9.2792 - accuracy: 0.1046 - val_loss: 9.8466 - val_accuracy: 0.0882 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 9.1939 - accuracy: 0.1037 - val_loss: 9.7539 - val_accuracy: 0.0918 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 9.0776 - accuracy: 0.1047 - val_loss: 9.3236 - val_accuracy: 0.0982 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 8.9927 - accuracy: 0.1053 - val_loss: 9.3002 - val_accuracy: 0.0917 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.8677 - accuracy: 0.1051 - val_loss: 9.2384 - val_accuracy: 0.0874 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.7920 - accuracy: 0.1034 - val_loss: 9.9381 - val_accuracy: 0.0812 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 8.6887 - accuracy: 0.1050 - val_loss: 9.0736 - val_accuracy: 0.0903 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.7032 - accuracy: 0.1035 - val_loss: 9.1585 - val_accuracy: 0.0867 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 8.5553 - accuracy: 0.1032 - val_loss: 8.9033 - val_accuracy: 0.0922 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.5337 - accuracy: 0.1033 - val_loss: 9.5807 - val_accuracy: 0.0889 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.4099 - accuracy: 0.1049 - val_loss: 8.9630 - val_accuracy: 0.0892 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.4158 - accuracy: 0.1028 - val_loss: 8.6389 - val_accuracy: 0.0916 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.3669 - accuracy: 0.1010 - val_loss: 8.6454 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 432s 231ms/step - loss: 8.3218 - accuracy: 0.1024 - val_loss: 8.9264 - val_accuracy: 0.0830 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.2552 - accuracy: 0.1024 - val_loss: 8.9597 - val_accuracy: 0.0876 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.2141 - accuracy: 0.1025 - val_loss: 8.4915 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 8.1667 - accuracy: 0.1026 - val_loss: 8.4131 - val_accuracy: 0.0972 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.1057 - accuracy: 0.1011 - val_loss: 8.6032 - val_accuracy: 0.0907 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.1013 - accuracy: 0.1013 - val_loss: 8.3505 - val_accuracy: 0.0930 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.0176 - accuracy: 0.1018 - val_loss: 8.6169 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 8.0326 - accuracy: 0.1019 - val_loss: 8.4780 - val_accuracy: 0.0893 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 7.9324 - accuracy: 0.1021 - val_loss: 8.3707 - val_accuracy: 0.0882 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 7.9405 - accuracy: 0.1008 - val_loss: 8.4077 - val_accuracy: 0.0896 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 7.8747 - accuracy: 0.1018 - val_loss: 8.2107 - val_accuracy: 0.0941 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 7.8549 - accuracy: 0.1014 - val_loss: 8.3011 - val_accuracy: 0.0887 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 7.7886 - accuracy: 0.1019 - val_loss: 8.3945 - val_accuracy: 0.0846 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 7.8116 - accuracy: 0.1003 - val_loss: 8.2119 - val_accuracy: 0.0884 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = resnet50v2_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "resnet50v2_model.save(os.path.join('models', 'RESNET50_30epoch.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5c9ee3-e2bc-4409-a848-cc01bf1d50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 21s - loss: 9.1470 - accuracy: 0.1128WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 14s 27ms/step - loss: 9.1434 - accuracy: 0.1128\n",
      "{'loss': 9.143423080444336, 'accuracy': 0.1128000020980835}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = resnet50v2_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(resnet50v2_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6675129a-1500-4443-9d6b-3f6757c531ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 777s 413ms/step - loss: 20.8447 - accuracy: 0.0173 - val_loss: 21.2633 - val_accuracy: 0.0210 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 18.9357 - accuracy: 0.0226 - val_loss: 17.5337 - val_accuracy: 0.0211 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 18.5674 - accuracy: 0.0267 - val_loss: 19.3466 - val_accuracy: 0.0246 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 778s 415ms/step - loss: 18.4079 - accuracy: 0.0285 - val_loss: 16.4905 - val_accuracy: 0.0307 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 783s 418ms/step - loss: 18.4307 - accuracy: 0.0283 - val_loss: 19.0468 - val_accuracy: 0.0336 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 779s 416ms/step - loss: 18.0618 - accuracy: 0.0293 - val_loss: 17.8902 - val_accuracy: 0.0301 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 18.1329 - accuracy: 0.0308 - val_loss: 18.6937 - val_accuracy: 0.0267 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 18.1983 - accuracy: 0.0314 - val_loss: 17.5690 - val_accuracy: 0.0313 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 18.1140 - accuracy: 0.0314\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 18.1140 - accuracy: 0.0314 - val_loss: 18.2871 - val_accuracy: 0.0320 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 773s 412ms/step - loss: 6.6659 - accuracy: 0.0640 - val_loss: 6.4385 - val_accuracy: 0.0573 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 6.0528 - accuracy: 0.0649 - val_loss: 6.1578 - val_accuracy: 0.0618 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 5.9359 - accuracy: 0.0647 - val_loss: 6.0406 - val_accuracy: 0.0628 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 775s 413ms/step - loss: 5.8369 - accuracy: 0.0658 - val_loss: 5.9592 - val_accuracy: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 779s 415ms/step - loss: 5.7476 - accuracy: 0.0660 - val_loss: 5.8878 - val_accuracy: 0.0657 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 775s 413ms/step - loss: 5.7077 - accuracy: 0.0663 - val_loss: 5.8818 - val_accuracy: 0.0592 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 770s 411ms/step - loss: 5.6573 - accuracy: 0.0667 - val_loss: 5.8122 - val_accuracy: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 769s 410ms/step - loss: 5.6322 - accuracy: 0.0664 - val_loss: 5.7931 - val_accuracy: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.5918 - accuracy: 0.0664 - val_loss: 5.6939 - val_accuracy: 0.0589 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 775s 414ms/step - loss: 5.5849 - accuracy: 0.0657 - val_loss: 5.7979 - val_accuracy: 0.0574 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 771s 411ms/step - loss: 5.5493 - accuracy: 0.0664 - val_loss: 5.7041 - val_accuracy: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 773s 412ms/step - loss: 5.5343 - accuracy: 0.0658 - val_loss: 5.7079 - val_accuracy: 0.0659 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.5269 - accuracy: 0.0660 - val_loss: 5.7792 - val_accuracy: 0.0595 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4847 - accuracy: 0.0674 - val_loss: 5.6438 - val_accuracy: 0.0615 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.4804 - accuracy: 0.0653 - val_loss: 5.5609 - val_accuracy: 0.0640 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4600 - accuracy: 0.0655 - val_loss: 5.6008 - val_accuracy: 0.0586 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 778s 415ms/step - loss: 5.4664 - accuracy: 0.0644 - val_loss: 5.6829 - val_accuracy: 0.0596 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.4397 - accuracy: 0.0666 - val_loss: 5.6537 - val_accuracy: 0.0569 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 5.4496 - accuracy: 0.0657 - val_loss: 5.6918 - val_accuracy: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 5.4095 - accuracy: 0.0670\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4095 - accuracy: 0.0670 - val_loss: 5.6177 - val_accuracy: 0.0597 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 761s 406ms/step - loss: 4.7180 - accuracy: 0.0897 - val_loss: 4.8774 - val_accuracy: 0.0792 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 775s 414ms/step - loss: 4.6793 - accuracy: 0.0917 - val_loss: 4.8876 - val_accuracy: 0.0795 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 767s 409ms/step - loss: 4.6717 - accuracy: 0.0905 - val_loss: 4.8811 - val_accuracy: 0.0766 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 843s 450ms/step - loss: 4.6657 - accuracy: 0.0917 - val_loss: 4.8604 - val_accuracy: 0.0835 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 4.6620 - accuracy: 0.0926 - val_loss: 4.8607 - val_accuracy: 0.0799 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 779s 415ms/step - loss: 4.6571 - accuracy: 0.0918 - val_loss: 4.8599 - val_accuracy: 0.0779 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 788s 420ms/step - loss: 4.6528 - accuracy: 0.0938 - val_loss: 4.8304 - val_accuracy: 0.0775 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 784s 418ms/step - loss: 4.6609 - accuracy: 0.0909 - val_loss: 4.8419 - val_accuracy: 0.0834 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "1423/1875 [=====================>........] - ETA: 2:53 - loss: 4.6510 - accuracy: 0.0925"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_861427]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43minceptionv3_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen_inceptionV3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen_inceptionV3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_steps_per_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_steps_per_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_861427]"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = inceptionv3_model.fit(\n",
    "    train_gen_inceptionV3, validation_data=valid_gen_inceptionV3, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback])\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "inceptionv3_model.save(os.path.join('models', 'InceptionV3_30epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5847b3-8afa-4656-ba89-5dc741eb96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run out of resources for last run, but as you can see, highest accuracy from alst epoch 37 is 0.091\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0813cd3c-1c28-45e4-b99e-c9088fde7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# test_res = inceptionv3_model.evaluate(test_gen_inceptionV3, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# # Print the results as a dictionary {<metric name>: <value>}\n",
    "# test_res_dict = dict(zip(inceptionv3_model.metrics_names, test_res))\n",
    "# print(test_res_dict)\n",
    "\n",
    "\n",
    "# can't run this part saddly, run out of resources during training and not enough time left\n",
    "# luckly it's only inceptionV3, so it's just something extra I was trying to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320508c2-2b49-46a4-9e36-84f24f5a3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171317808/171317808 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16,ResNet101V2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "def create_ResNet101V2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet101V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet101V2_model = create_ResNet101V2_model()\n",
    "resnet101V2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg16_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg16_model = create_vgg16_model()\n",
    "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg16_model.summary()\n",
    "#resnet101V2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64749333-57ae-4145-b5fc-729a1d96bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 427s 227ms/step - loss: 78.4746 - accuracy: 0.3447 - val_loss: 96.5718 - val_accuracy: 0.2804 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 75.3584 - accuracy: 0.3487 - val_loss: 94.3162 - val_accuracy: 0.2927 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 427s 228ms/step - loss: 72.5291 - accuracy: 0.3503 - val_loss: 91.0569 - val_accuracy: 0.2901 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 428s 228ms/step - loss: 69.6988 - accuracy: 0.3573 - val_loss: 89.8522 - val_accuracy: 0.2858 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 429s 229ms/step - loss: 68.4815 - accuracy: 0.3567 - val_loss: 86.6571 - val_accuracy: 0.2898 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 66.9124 - accuracy: 0.3592 - val_loss: 85.6055 - val_accuracy: 0.2947 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 445s 237ms/step - loss: 64.7644 - accuracy: 0.3613 - val_loss: 83.7820 - val_accuracy: 0.2918 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 491s 262ms/step - loss: 62.9989 - accuracy: 0.3657 - val_loss: 82.4464 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 504s 269ms/step - loss: 62.3776 - accuracy: 0.3647 - val_loss: 82.3235 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 60.5862 - accuracy: 0.3681 - val_loss: 80.3493 - val_accuracy: 0.2951 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 432s 231ms/step - loss: 59.0769 - accuracy: 0.3703 - val_loss: 78.6972 - val_accuracy: 0.2953 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 58.2696 - accuracy: 0.3723 - val_loss: 77.7683 - val_accuracy: 0.2928 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 57.3258 - accuracy: 0.3727 - val_loss: 76.0018 - val_accuracy: 0.2999 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 56.3481 - accuracy: 0.3711 - val_loss: 75.4306 - val_accuracy: 0.2969 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 55.2503 - accuracy: 0.3743 - val_loss: 74.4259 - val_accuracy: 0.2999 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=15\n",
    "history = vgg16_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "vgg16_model.save(os.path.join('models', 'vgg16_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f87e7a9-292a-4219-a7c9-de57f6f6891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 26s - loss: 89.4468 - accuracy: 0.3042WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 18s 34ms/step - loss: 89.4672 - accuracy: 0.3041\n",
      "{'loss': 89.46724700927734, 'accuracy': 0.30410000681877136}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = vgg16_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(vgg16_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4fcefa-03f6-454d-9a19-05c69a04fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 438s 231ms/step - loss: 164.6752 - accuracy: 0.0154 - val_loss: 161.7328 - val_accuracy: 0.0209 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 165.1906 - accuracy: 0.0213 - val_loss: 153.2496 - val_accuracy: 0.0193 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 164.0427 - accuracy: 0.0245 - val_loss: 156.5984 - val_accuracy: 0.0268 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 161.8978 - accuracy: 0.0263 - val_loss: 174.6801 - val_accuracy: 0.0319 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 164.6766 - accuracy: 0.0274 - val_loss: 154.1006 - val_accuracy: 0.0281 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 439s 234ms/step - loss: 163.6740 - accuracy: 0.0281 - val_loss: 149.5718 - val_accuracy: 0.0339 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 158.7778 - accuracy: 0.0302 - val_loss: 156.4455 - val_accuracy: 0.0345 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 161.0377 - accuracy: 0.0308 - val_loss: 143.7287 - val_accuracy: 0.0321 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 160.1025 - accuracy: 0.0320 - val_loss: 147.1398 - val_accuracy: 0.0327 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 157.4424 - accuracy: 0.0324 - val_loss: 146.6907 - val_accuracy: 0.0407 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 157.1825 - accuracy: 0.0337 - val_loss: 153.1526 - val_accuracy: 0.0355 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 158.3779 - accuracy: 0.0336 - val_loss: 141.9130 - val_accuracy: 0.0353 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 154.9676 - accuracy: 0.0344 - val_loss: 161.0751 - val_accuracy: 0.0335 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 159.0903 - accuracy: 0.0342 - val_loss: 137.5424 - val_accuracy: 0.0431 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 154.9745 - accuracy: 0.0363 - val_loss: 152.7636 - val_accuracy: 0.0243 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "n_epochs=15\n",
    "history = resnet101V2_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "resnet101V2_model.save(os.path.join('models', 'resnet101V2_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f70683-3971-479c-a84b-883202773bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 39s - loss: 154.1744 - accuracy: 0.0356WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 27s 51ms/step - loss: 154.1031 - accuracy: 0.0356\n",
      "{'loss': 154.10311889648438, 'accuracy': 0.035599999129772186}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = resnet101V2_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(resnet101V2_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b23cb0-a23f-4a33-b30e-9db479e014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's inceptionV4\n",
    "# please refer to the JDong_HW5_InceptionV4 notebook for results\n",
    "# I had to use pytorch for it and not tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
