{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f325b1-cdf4-4e5d-94e9-ee4275091ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data','tiny-imagenet-200.zip')):\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','tiny-imagenet-200.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'tiny-imagenet-200')):\n",
    "    with zipfile.ZipFile(os.path.join('data','tiny-imagenet-200.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45be974c-80fa-42a8-a9ed-486c7fd29068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed = 1997\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a913a6dd-4785-4ed7-9317-47df3b6e141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10.0\n",
      "  Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\docto\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.10.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (23.2)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl.metadata (806 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (1.62.1)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
      "Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: keras, tensorboard-data-server, protobuf, tensorboard, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.1.1\n",
      "    Uninstalling keras-3.1.1:\n",
      "      Successfully uninstalled keras-3.1.1\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed keras-2.10.0 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-datasets 4.9.4 requires tqdm, which is not installed.\n",
      "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d48f2b-c04c-43b0-85ed-160f59f34d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n",
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_test_labels_df(test_labels_path):\n",
    "    \"\"\" Reading the test data labels for all files in the test set as a data frame \"\"\"\n",
    "    test_df = pd.read_csv(test_labels_path, sep='\\t', index_col=None, header=None)\n",
    "    test_df = test_df.iloc[:,[0,1]].rename({0:\"filename\", 1:\"class\"}, axis=1)\n",
    "    return test_df\n",
    "\n",
    "def get_train_valid_test_data_generators(batch_size, target_size):\n",
    "    \"\"\" Get the training/validation/testing data generators \"\"\"\n",
    "    \n",
    "    # Defining a data-augmenting image data generator and a standard image data generator\n",
    "    image_gen_aug = ImageDataGenerator(\n",
    "        samplewise_center=False, rotation_range=30, width_shift_range=0.2,\n",
    "        height_shift_range=0.2, brightness_range=(0.5,1.5), shear_range=5, \n",
    "        zoom_range=0.2, horizontal_flip=True, fill_mode='constant', cval=127.5, \n",
    "        validation_split=0.1\n",
    "    )\n",
    "    image_gen = ImageDataGenerator(samplewise_center=False)\n",
    "    \n",
    "    # Define a training data generator\n",
    "    partial_flow_func = partial(\n",
    "        image_gen_aug.flow_from_directory, \n",
    "        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n",
    "        target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, \n",
    "        shuffle=True, seed=random_seed)\n",
    "    \n",
    "    # Get the training data subset\n",
    "    train_gen = partial_flow_func(subset='training')\n",
    "    # Get the validation data subset\n",
    "    valid_gen = partial_flow_func(subset='validation')    \n",
    "\n",
    "    # Defining the test data generator\n",
    "    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  'val', 'val_annotations.txt'))\n",
    "    test_gen = image_gen.flow_from_dataframe(\n",
    "        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "\n",
    "batch_size = 48\n",
    "target_size = (224,224)\n",
    "# Getting the train,valid, test data generators\n",
    "train_gen, valid_gen, test_gen = get_train_valid_test_data_generators(batch_size, target_size)\n",
    "# Modifying the data generators to fit the model targets\n",
    "train_gen_inceptionV3, valid_gen_inceptionV3, test_gen_inceptionV3 = get_train_valid_test_data_generators(batch_size,(299,299))\n",
    "\n",
    "with open(os.path.join('data','class_indices'), 'wb') as f:\n",
    "    pickle.dump(train_gen.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7466a4-7a05-4e71-bdb4-dcb1ab0f79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19,ResNet50V2,InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "def create_inceptionv3_model(input_shape=(299, 299, 3), num_classes=200):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "inceptionv3_model = create_inceptionv3_model()\n",
    "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_resnet50v2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet50v2_model = create_resnet50v2_model()\n",
    "resnet50v2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg19_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg19_model = create_vgg19_model()\n",
    "vgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg19_model.summary()\n",
    "#resnet50v2_model.summary()\n",
    "#inceptionv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa9a727-56e5-462a-a2a3-352af3aeb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=25)\n",
    "lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n",
    ")\n",
    "def get_steps_per_epoch(n_data, batch_size):\n",
    "    \"\"\" Given the data size and batch size, gives the number of steps to travers the full dataset \"\"\"\n",
    "    if n_data%batch_size==0:\n",
    "        return int(n_data/batch_size)\n",
    "    else:\n",
    "        return int(n_data*1.0/batch_size)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179bf772-6b5d-42e4-8467-e2b03150eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 437s 230ms/step - loss: 73.8320 - accuracy: 0.1364 - val_loss: 84.5855 - val_accuracy: 0.1780 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 87.3286 - accuracy: 0.2016 - val_loss: 96.6730 - val_accuracy: 0.2017 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 93.7164 - accuracy: 0.2270 - val_loss: 104.8548 - val_accuracy: 0.2191 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 97.4487 - accuracy: 0.2436 - val_loss: 108.5414 - val_accuracy: 0.2216 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 100.7292 - accuracy: 0.2532 - val_loss: 113.6165 - val_accuracy: 0.2301 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 102.9009 - accuracy: 0.2622\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 102.9009 - accuracy: 0.2622 - val_loss: 118.0585 - val_accuracy: 0.2331 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 453s 242ms/step - loss: 83.4226 - accuracy: 0.3100 - val_loss: 95.3592 - val_accuracy: 0.2741 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 75.8246 - accuracy: 0.3265 - val_loss: 91.1789 - val_accuracy: 0.2810 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 71.6984 - accuracy: 0.3329 - val_loss: 87.5145 - val_accuracy: 0.2793 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 68.5497 - accuracy: 0.3398 - val_loss: 84.4488 - val_accuracy: 0.2834 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 65.8935 - accuracy: 0.3440 - val_loss: 81.7813 - val_accuracy: 0.2865 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 63.3783 - accuracy: 0.3495 - val_loss: 80.3479 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 61.9323 - accuracy: 0.3516 - val_loss: 76.7771 - val_accuracy: 0.2938 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 60.0185 - accuracy: 0.3519 - val_loss: 76.7582 - val_accuracy: 0.2874 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 58.1976 - accuracy: 0.3547 - val_loss: 74.2841 - val_accuracy: 0.2948 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 56.8493 - accuracy: 0.3555 - val_loss: 71.9456 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 55.5574 - accuracy: 0.3565 - val_loss: 73.6436 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 54.2527 - accuracy: 0.3609 - val_loss: 71.6941 - val_accuracy: 0.2900 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 53.3031 - accuracy: 0.3618 - val_loss: 70.0027 - val_accuracy: 0.2955 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 52.4658 - accuracy: 0.3602 - val_loss: 68.6842 - val_accuracy: 0.2927 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 50.8566 - accuracy: 0.3667 - val_loss: 67.4520 - val_accuracy: 0.2928 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 50.3913 - accuracy: 0.3645 - val_loss: 66.7736 - val_accuracy: 0.2914 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 49.3019 - accuracy: 0.3668 - val_loss: 66.1333 - val_accuracy: 0.2925 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 48.4147 - accuracy: 0.3673 - val_loss: 64.9001 - val_accuracy: 0.2950 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 47.4963 - accuracy: 0.3686 - val_loss: 63.8421 - val_accuracy: 0.2953 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 47.0168 - accuracy: 0.3696 - val_loss: 63.1961 - val_accuracy: 0.3016 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 46.0692 - accuracy: 0.3698 - val_loss: 62.8753 - val_accuracy: 0.2938 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 45.5665 - accuracy: 0.3720 - val_loss: 62.7460 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 44.7027 - accuracy: 0.3724 - val_loss: 60.3570 - val_accuracy: 0.2937 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 44.1026 - accuracy: 0.3715 - val_loss: 60.4472 - val_accuracy: 0.2968 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 43.3765 - accuracy: 0.3746 - val_loss: 59.8975 - val_accuracy: 0.2903 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 42.8766 - accuracy: 0.3759 - val_loss: 58.5216 - val_accuracy: 0.2936 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 42.3922 - accuracy: 0.3751 - val_loss: 58.3608 - val_accuracy: 0.2954 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 41.9932 - accuracy: 0.3749 - val_loss: 58.1317 - val_accuracy: 0.2926 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 41.1064 - accuracy: 0.3773 - val_loss: 57.2087 - val_accuracy: 0.2993 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 40.7336 - accuracy: 0.3770 - val_loss: 56.2209 - val_accuracy: 0.2948 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 40.4248 - accuracy: 0.3771 - val_loss: 55.9744 - val_accuracy: 0.2892 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 440s 235ms/step - loss: 39.6314 - accuracy: 0.3787 - val_loss: 55.6802 - val_accuracy: 0.3023 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 39.2698 - accuracy: 0.3784 - val_loss: 55.3899 - val_accuracy: 0.2936 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 38.7091 - accuracy: 0.3786 - val_loss: 55.1386 - val_accuracy: 0.2944 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 38.3287 - accuracy: 0.3812 - val_loss: 53.4432 - val_accuracy: 0.3005 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 37.8199 - accuracy: 0.3822 - val_loss: 53.4589 - val_accuracy: 0.2931 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 37.3281 - accuracy: 0.3838 - val_loss: 53.2803 - val_accuracy: 0.2980 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 37.1303 - accuracy: 0.3821 - val_loss: 52.6261 - val_accuracy: 0.2907 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 36.6186 - accuracy: 0.3809 - val_loss: 52.7623 - val_accuracy: 0.2988 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 438s 234ms/step - loss: 36.1626 - accuracy: 0.3830 - val_loss: 52.1278 - val_accuracy: 0.2883 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 35.8713 - accuracy: 0.3825 - val_loss: 51.0938 - val_accuracy: 0.2971 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 35.3559 - accuracy: 0.3825 - val_loss: 51.5518 - val_accuracy: 0.2940 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 35.1754 - accuracy: 0.3831 - val_loss: 50.6364 - val_accuracy: 0.2920 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 34.9892 - accuracy: 0.3845 - val_loss: 50.3060 - val_accuracy: 0.2967 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = vgg19_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "vgg19_model.save(os.path.join('models', 'VGG19_30epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084c1084-29ae-4cbd-a657-46d31ad958ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 32s - loss: 62.8520 - accuracy: 0.3066WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 22s 43ms/step - loss: 62.8535 - accuracy: 0.3064\n",
      "{'loss': 62.85350036621094, 'accuracy': 0.30640000104904175}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = vgg19_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(vgg19_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d82bfb2c-5132-48ce-853f-be2d996348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 433s 230ms/step - loss: 64.6342 - accuracy: 0.0218 - val_loss: 61.0181 - val_accuracy: 0.0270 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 62.2299 - accuracy: 0.0304 - val_loss: 58.3081 - val_accuracy: 0.0319 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 61.2347 - accuracy: 0.0357 - val_loss: 58.4649 - val_accuracy: 0.0446 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 60.4660 - accuracy: 0.0382 - val_loss: 55.1613 - val_accuracy: 0.0398 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 60.5263 - accuracy: 0.0407 - val_loss: 70.9044 - val_accuracy: 0.0347 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 60.1795 - accuracy: 0.0417 - val_loss: 56.4137 - val_accuracy: 0.0432 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 58.8732 - accuracy: 0.0426 - val_loss: 55.3189 - val_accuracy: 0.0454 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 59.6477 - accuracy: 0.0453 - val_loss: 60.3410 - val_accuracy: 0.0465 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 58.0646 - accuracy: 0.0461 - val_loss: 54.2681 - val_accuracy: 0.0506 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 58.8614 - accuracy: 0.0473 - val_loss: 58.2778 - val_accuracy: 0.0443 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 58.3930 - accuracy: 0.0478 - val_loss: 55.3911 - val_accuracy: 0.0472 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 57.2473 - accuracy: 0.0494 - val_loss: 55.6855 - val_accuracy: 0.0421 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 58.0823 - accuracy: 0.0502 - val_loss: 59.6118 - val_accuracy: 0.0431 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 57.9131 - accuracy: 0.0505\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 438s 234ms/step - loss: 57.9131 - accuracy: 0.0505 - val_loss: 65.2486 - val_accuracy: 0.0593 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 13.3814 - accuracy: 0.1136 - val_loss: 11.9698 - val_accuracy: 0.1025 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 10.8401 - accuracy: 0.1131 - val_loss: 11.9179 - val_accuracy: 0.0948 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 10.5469 - accuracy: 0.1097 - val_loss: 11.3938 - val_accuracy: 0.0949 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 10.2307 - accuracy: 0.1086 - val_loss: 10.9398 - val_accuracy: 0.0920 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 10.0183 - accuracy: 0.1055 - val_loss: 10.8854 - val_accuracy: 0.0900 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 9.8491 - accuracy: 0.1063 - val_loss: 10.1321 - val_accuracy: 0.0972 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 9.6378 - accuracy: 0.1064 - val_loss: 10.0964 - val_accuracy: 0.1019 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 9.5248 - accuracy: 0.1061 - val_loss: 9.8412 - val_accuracy: 0.0973 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 9.3896 - accuracy: 0.1059 - val_loss: 10.0998 - val_accuracy: 0.0985 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 9.2792 - accuracy: 0.1046 - val_loss: 9.8466 - val_accuracy: 0.0882 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 9.1939 - accuracy: 0.1037 - val_loss: 9.7539 - val_accuracy: 0.0918 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 9.0776 - accuracy: 0.1047 - val_loss: 9.3236 - val_accuracy: 0.0982 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 8.9927 - accuracy: 0.1053 - val_loss: 9.3002 - val_accuracy: 0.0917 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.8677 - accuracy: 0.1051 - val_loss: 9.2384 - val_accuracy: 0.0874 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.7920 - accuracy: 0.1034 - val_loss: 9.9381 - val_accuracy: 0.0812 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 8.6887 - accuracy: 0.1050 - val_loss: 9.0736 - val_accuracy: 0.0903 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.7032 - accuracy: 0.1035 - val_loss: 9.1585 - val_accuracy: 0.0867 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 8.5553 - accuracy: 0.1032 - val_loss: 8.9033 - val_accuracy: 0.0922 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.5337 - accuracy: 0.1033 - val_loss: 9.5807 - val_accuracy: 0.0889 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.4099 - accuracy: 0.1049 - val_loss: 8.9630 - val_accuracy: 0.0892 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.4158 - accuracy: 0.1028 - val_loss: 8.6389 - val_accuracy: 0.0916 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 8.3669 - accuracy: 0.1010 - val_loss: 8.6454 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 432s 231ms/step - loss: 8.3218 - accuracy: 0.1024 - val_loss: 8.9264 - val_accuracy: 0.0830 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.2552 - accuracy: 0.1024 - val_loss: 8.9597 - val_accuracy: 0.0876 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 8.2141 - accuracy: 0.1025 - val_loss: 8.4915 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 8.1667 - accuracy: 0.1026 - val_loss: 8.4131 - val_accuracy: 0.0972 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.1057 - accuracy: 0.1011 - val_loss: 8.6032 - val_accuracy: 0.0907 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.1013 - accuracy: 0.1013 - val_loss: 8.3505 - val_accuracy: 0.0930 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 8.0176 - accuracy: 0.1018 - val_loss: 8.6169 - val_accuracy: 0.0858 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 8.0326 - accuracy: 0.1019 - val_loss: 8.4780 - val_accuracy: 0.0893 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 7.9324 - accuracy: 0.1021 - val_loss: 8.3707 - val_accuracy: 0.0882 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 7.9405 - accuracy: 0.1008 - val_loss: 8.4077 - val_accuracy: 0.0896 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 433s 231ms/step - loss: 7.8747 - accuracy: 0.1018 - val_loss: 8.2107 - val_accuracy: 0.0941 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 7.8549 - accuracy: 0.1014 - val_loss: 8.3011 - val_accuracy: 0.0887 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 430s 230ms/step - loss: 7.7886 - accuracy: 0.1019 - val_loss: 8.3945 - val_accuracy: 0.0846 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 7.8116 - accuracy: 0.1003 - val_loss: 8.2119 - val_accuracy: 0.0884 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = resnet50v2_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "resnet50v2_model.save(os.path.join('models', 'RESNET50_30epoch.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5c9ee3-e2bc-4409-a848-cc01bf1d50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 21s - loss: 9.1470 - accuracy: 0.1128WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 14s 27ms/step - loss: 9.1434 - accuracy: 0.1128\n",
      "{'loss': 9.143423080444336, 'accuracy': 0.1128000020980835}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = resnet50v2_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(resnet50v2_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6675129a-1500-4443-9d6b-3f6757c531ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 777s 413ms/step - loss: 20.8447 - accuracy: 0.0173 - val_loss: 21.2633 - val_accuracy: 0.0210 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 18.9357 - accuracy: 0.0226 - val_loss: 17.5337 - val_accuracy: 0.0211 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 18.5674 - accuracy: 0.0267 - val_loss: 19.3466 - val_accuracy: 0.0246 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 778s 415ms/step - loss: 18.4079 - accuracy: 0.0285 - val_loss: 16.4905 - val_accuracy: 0.0307 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 783s 418ms/step - loss: 18.4307 - accuracy: 0.0283 - val_loss: 19.0468 - val_accuracy: 0.0336 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 779s 416ms/step - loss: 18.0618 - accuracy: 0.0293 - val_loss: 17.8902 - val_accuracy: 0.0301 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 18.1329 - accuracy: 0.0308 - val_loss: 18.6937 - val_accuracy: 0.0267 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 18.1983 - accuracy: 0.0314 - val_loss: 17.5690 - val_accuracy: 0.0313 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 18.1140 - accuracy: 0.0314\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 18.1140 - accuracy: 0.0314 - val_loss: 18.2871 - val_accuracy: 0.0320 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 773s 412ms/step - loss: 6.6659 - accuracy: 0.0640 - val_loss: 6.4385 - val_accuracy: 0.0573 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 6.0528 - accuracy: 0.0649 - val_loss: 6.1578 - val_accuracy: 0.0618 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 777s 414ms/step - loss: 5.9359 - accuracy: 0.0647 - val_loss: 6.0406 - val_accuracy: 0.0628 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 775s 413ms/step - loss: 5.8369 - accuracy: 0.0658 - val_loss: 5.9592 - val_accuracy: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 779s 415ms/step - loss: 5.7476 - accuracy: 0.0660 - val_loss: 5.8878 - val_accuracy: 0.0657 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 775s 413ms/step - loss: 5.7077 - accuracy: 0.0663 - val_loss: 5.8818 - val_accuracy: 0.0592 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 770s 411ms/step - loss: 5.6573 - accuracy: 0.0667 - val_loss: 5.8122 - val_accuracy: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 769s 410ms/step - loss: 5.6322 - accuracy: 0.0664 - val_loss: 5.7931 - val_accuracy: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.5918 - accuracy: 0.0664 - val_loss: 5.6939 - val_accuracy: 0.0589 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 775s 414ms/step - loss: 5.5849 - accuracy: 0.0657 - val_loss: 5.7979 - val_accuracy: 0.0574 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 771s 411ms/step - loss: 5.5493 - accuracy: 0.0664 - val_loss: 5.7041 - val_accuracy: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 773s 412ms/step - loss: 5.5343 - accuracy: 0.0658 - val_loss: 5.7079 - val_accuracy: 0.0659 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.5269 - accuracy: 0.0660 - val_loss: 5.7792 - val_accuracy: 0.0595 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4847 - accuracy: 0.0674 - val_loss: 5.6438 - val_accuracy: 0.0615 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.4804 - accuracy: 0.0653 - val_loss: 5.5609 - val_accuracy: 0.0640 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4600 - accuracy: 0.0655 - val_loss: 5.6008 - val_accuracy: 0.0586 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 778s 415ms/step - loss: 5.4664 - accuracy: 0.0644 - val_loss: 5.6829 - val_accuracy: 0.0596 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 774s 413ms/step - loss: 5.4397 - accuracy: 0.0666 - val_loss: 5.6537 - val_accuracy: 0.0569 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 5.4496 - accuracy: 0.0657 - val_loss: 5.6918 - val_accuracy: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 5.4095 - accuracy: 0.0670\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1875/1875 [==============================] - 772s 412ms/step - loss: 5.4095 - accuracy: 0.0670 - val_loss: 5.6177 - val_accuracy: 0.0597 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 761s 406ms/step - loss: 4.7180 - accuracy: 0.0897 - val_loss: 4.8774 - val_accuracy: 0.0792 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 775s 414ms/step - loss: 4.6793 - accuracy: 0.0917 - val_loss: 4.8876 - val_accuracy: 0.0795 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 767s 409ms/step - loss: 4.6717 - accuracy: 0.0905 - val_loss: 4.8811 - val_accuracy: 0.0766 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 843s 450ms/step - loss: 4.6657 - accuracy: 0.0917 - val_loss: 4.8604 - val_accuracy: 0.0835 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 776s 414ms/step - loss: 4.6620 - accuracy: 0.0926 - val_loss: 4.8607 - val_accuracy: 0.0799 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 779s 415ms/step - loss: 4.6571 - accuracy: 0.0918 - val_loss: 4.8599 - val_accuracy: 0.0779 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 788s 420ms/step - loss: 4.6528 - accuracy: 0.0938 - val_loss: 4.8304 - val_accuracy: 0.0775 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 784s 418ms/step - loss: 4.6609 - accuracy: 0.0909 - val_loss: 4.8419 - val_accuracy: 0.0834 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "1423/1875 [=====================>........] - ETA: 2:53 - loss: 4.6510 - accuracy: 0.0925"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_861427]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43minceptionv3_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen_inceptionV3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen_inceptionV3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_steps_per_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_steps_per_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n\n  File \"C:\\Users\\docto\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 384, in _get_batches_of_transformed_samples\n    x = self.image_data_generator.apply_transform(x, params)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2043, in apply_transform\n    x = apply_brightness_shift(\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 2435, in apply_brightness_shift\n    x = image_utils.img_to_array(x)\n\n  File \"C:\\Users\\docto\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 324, in img_to_array\n    x = np.asarray(img, dtype=dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.02 MiB for an array with shape (299, 299, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_861427]"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "history = inceptionv3_model.fit(\n",
    "    train_gen_inceptionV3, validation_data=valid_gen_inceptionV3, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback])\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "inceptionv3_model.save(os.path.join('models', 'InceptionV3_30epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5847b3-8afa-4656-ba89-5dc741eb96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run out of resources for last run, but as you can see, highest accuracy from last epoch 37 is 0.091\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0813cd3c-1c28-45e4-b99e-c9088fde7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# test_res = inceptionv3_model.evaluate(test_gen_inceptionV3, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# # Print the results as a dictionary {<metric name>: <value>}\n",
    "# test_res_dict = dict(zip(inceptionv3_model.metrics_names, test_res))\n",
    "# print(test_res_dict)\n",
    "\n",
    "\n",
    "# can't run this part saddly, run out of resources during training and not enough time left\n",
    "# luckly it's only inceptionV3, so it's just something extra I was trying to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320508c2-2b49-46a4-9e36-84f24f5a3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171317808/171317808 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16,ResNet101V2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "def create_ResNet101V2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet101V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet101V2_model = create_ResNet101V2_model()\n",
    "resnet101V2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg16_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg16_model = create_vgg16_model()\n",
    "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg16_model.summary()\n",
    "#resnet101V2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64749333-57ae-4145-b5fc-729a1d96bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 427s 227ms/step - loss: 78.4746 - accuracy: 0.3447 - val_loss: 96.5718 - val_accuracy: 0.2804 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 75.3584 - accuracy: 0.3487 - val_loss: 94.3162 - val_accuracy: 0.2927 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 427s 228ms/step - loss: 72.5291 - accuracy: 0.3503 - val_loss: 91.0569 - val_accuracy: 0.2901 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 428s 228ms/step - loss: 69.6988 - accuracy: 0.3573 - val_loss: 89.8522 - val_accuracy: 0.2858 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 429s 229ms/step - loss: 68.4815 - accuracy: 0.3567 - val_loss: 86.6571 - val_accuracy: 0.2898 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 430s 229ms/step - loss: 66.9124 - accuracy: 0.3592 - val_loss: 85.6055 - val_accuracy: 0.2947 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 445s 237ms/step - loss: 64.7644 - accuracy: 0.3613 - val_loss: 83.7820 - val_accuracy: 0.2918 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 491s 262ms/step - loss: 62.9989 - accuracy: 0.3657 - val_loss: 82.4464 - val_accuracy: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 504s 269ms/step - loss: 62.3776 - accuracy: 0.3647 - val_loss: 82.3235 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 60.5862 - accuracy: 0.3681 - val_loss: 80.3493 - val_accuracy: 0.2951 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 432s 231ms/step - loss: 59.0769 - accuracy: 0.3703 - val_loss: 78.6972 - val_accuracy: 0.2953 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 58.2696 - accuracy: 0.3723 - val_loss: 77.7683 - val_accuracy: 0.2928 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 57.3258 - accuracy: 0.3727 - val_loss: 76.0018 - val_accuracy: 0.2999 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 434s 232ms/step - loss: 56.3481 - accuracy: 0.3711 - val_loss: 75.4306 - val_accuracy: 0.2969 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 432s 230ms/step - loss: 55.2503 - accuracy: 0.3743 - val_loss: 74.4259 - val_accuracy: 0.2999 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs=15\n",
    "history = vgg16_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "vgg16_model.save(os.path.join('models', 'vgg16_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f87e7a9-292a-4219-a7c9-de57f6f6891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 26s - loss: 89.4468 - accuracy: 0.3042WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 18s 34ms/step - loss: 89.4672 - accuracy: 0.3041\n",
      "{'loss': 89.46724700927734, 'accuracy': 0.30410000681877136}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = vgg16_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(vgg16_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4fcefa-03f6-454d-9a19-05c69a04fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 438s 231ms/step - loss: 164.6752 - accuracy: 0.0154 - val_loss: 161.7328 - val_accuracy: 0.0209 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 165.1906 - accuracy: 0.0213 - val_loss: 153.2496 - val_accuracy: 0.0193 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 164.0427 - accuracy: 0.0245 - val_loss: 156.5984 - val_accuracy: 0.0268 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 436s 233ms/step - loss: 161.8978 - accuracy: 0.0263 - val_loss: 174.6801 - val_accuracy: 0.0319 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 437s 233ms/step - loss: 164.6766 - accuracy: 0.0274 - val_loss: 154.1006 - val_accuracy: 0.0281 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 439s 234ms/step - loss: 163.6740 - accuracy: 0.0281 - val_loss: 149.5718 - val_accuracy: 0.0339 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 158.7778 - accuracy: 0.0302 - val_loss: 156.4455 - val_accuracy: 0.0345 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 436s 232ms/step - loss: 161.0377 - accuracy: 0.0308 - val_loss: 143.7287 - val_accuracy: 0.0321 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 160.1025 - accuracy: 0.0320 - val_loss: 147.1398 - val_accuracy: 0.0327 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 157.4424 - accuracy: 0.0324 - val_loss: 146.6907 - val_accuracy: 0.0407 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 434s 231ms/step - loss: 157.1825 - accuracy: 0.0337 - val_loss: 153.1526 - val_accuracy: 0.0355 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 431s 230ms/step - loss: 158.3779 - accuracy: 0.0336 - val_loss: 141.9130 - val_accuracy: 0.0353 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 154.9676 - accuracy: 0.0344 - val_loss: 161.0751 - val_accuracy: 0.0335 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 438s 233ms/step - loss: 159.0903 - accuracy: 0.0342 - val_loss: 137.5424 - val_accuracy: 0.0431 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 435s 232ms/step - loss: 154.9745 - accuracy: 0.0363 - val_loss: 152.7636 - val_accuracy: 0.0243 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "n_epochs=15\n",
    "history = resnet101V2_model.fit(\n",
    "    train_gen, validation_data=valid_gen, \n",
    "    steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "    validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "    epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    ")\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir(\"models\")\n",
    "resnet101V2_model.save(os.path.join('models', 'resnet101V2_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f70683-3971-479c-a84b-883202773bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/521 [==========>...................] - ETA: 39s - loss: 154.1744 - accuracy: 0.0356WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 521 batches). You may need to use the repeat() function when building your dataset.\n",
      "521/521 [==============================] - 27s 51ms/step - loss: 154.1031 - accuracy: 0.0356\n",
      "{'loss': 154.10311889648438, 'accuracy': 0.035599999129772186}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_res = resnet101V2_model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "\n",
    "# Print the results as a dictionary {<metric name>: <value>}\n",
    "test_res_dict = dict(zip(resnet101V2_model.metrics_names, test_res))\n",
    "print(test_res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b23cb0-a23f-4a33-b30e-9db479e014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's inceptionV4\n",
    "# please refer to the JDong_HW5_InceptionV4 notebook for results\n",
    "# I had to use pytorch for it and not tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb258efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models are too large to upload to black board and thus kept local. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e102d394-fc2d-454a-a61b-d541136d15a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               5017800   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,732,488\n",
      "Trainable params: 5,017,800\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "VGG19\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               5017800   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,042,184\n",
      "Trainable params: 5,017,800\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Resnet50\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_8[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 200)          409800      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,974,600\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n",
      "Resnet100\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block6_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block7_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block7_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block7_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block7_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block7_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block7_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_out (Add)         (None, 14, 14, 1024  0           ['conv4_block6_out[0][0]',       \n",
      "                                )                                 'conv4_block7_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block7_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block8_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block8_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block8_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block8_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block8_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block8_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_out (Add)         (None, 14, 14, 1024  0           ['conv4_block7_out[0][0]',       \n",
      "                                )                                 'conv4_block8_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block8_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block9_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block9_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block9_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block9_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block9_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block9_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_out (Add)         (None, 14, 14, 1024  0           ['conv4_block8_out[0][0]',       \n",
      "                                )                                 'conv4_block9_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block9_out[0][0]']       \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block10_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block10_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block10_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block10_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block10_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_out (Add)        (None, 14, 14, 1024  0           ['conv4_block9_out[0][0]',       \n",
      "                                )                                 'conv4_block10_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block10_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block11_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block11_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block11_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block11_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block11_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block11_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_out (Add)        (None, 14, 14, 1024  0           ['conv4_block10_out[0][0]',      \n",
      "                                )                                 'conv4_block11_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block11_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block12_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block12_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block12_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block12_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block12_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block12_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_out (Add)        (None, 14, 14, 1024  0           ['conv4_block11_out[0][0]',      \n",
      "                                )                                 'conv4_block12_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block12_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block13_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block13_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block13_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block13_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block13_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block13_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_out (Add)        (None, 14, 14, 1024  0           ['conv4_block12_out[0][0]',      \n",
      "                                )                                 'conv4_block13_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block13_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block14_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block14_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block14_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block14_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block14_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block14_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_out (Add)        (None, 14, 14, 1024  0           ['conv4_block13_out[0][0]',      \n",
      "                                )                                 'conv4_block14_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block14_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block15_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block15_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block15_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block15_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block15_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block15_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_out (Add)        (None, 14, 14, 1024  0           ['conv4_block14_out[0][0]',      \n",
      "                                )                                 'conv4_block15_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block15_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block16_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block16_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block16_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block16_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block16_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block16_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_out (Add)        (None, 14, 14, 1024  0           ['conv4_block15_out[0][0]',      \n",
      "                                )                                 'conv4_block16_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block16_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block17_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block17_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block17_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block17_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block17_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block17_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_out (Add)        (None, 14, 14, 1024  0           ['conv4_block16_out[0][0]',      \n",
      "                                )                                 'conv4_block17_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block17_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block18_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block18_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block18_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block18_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block18_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block18_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_out (Add)        (None, 14, 14, 1024  0           ['conv4_block17_out[0][0]',      \n",
      "                                )                                 'conv4_block18_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block18_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block19_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block19_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block19_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block19_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block19_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block19_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_out (Add)        (None, 14, 14, 1024  0           ['conv4_block18_out[0][0]',      \n",
      "                                )                                 'conv4_block19_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block19_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block20_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block20_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block20_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block20_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block20_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block20_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_out (Add)        (None, 14, 14, 1024  0           ['conv4_block19_out[0][0]',      \n",
      "                                )                                 'conv4_block20_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block20_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block21_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block21_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block21_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block21_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block21_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block21_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_out (Add)        (None, 14, 14, 1024  0           ['conv4_block20_out[0][0]',      \n",
      "                                )                                 'conv4_block21_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block21_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block22_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block22_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block22_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block22_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block22_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block22_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_out (Add)        (None, 14, 14, 1024  0           ['conv4_block21_out[0][0]',      \n",
      "                                )                                 'conv4_block22_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block22_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block23_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block23_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block23_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 7, 7, 256)    589824      ['conv4_block23_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block23_2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['conv4_block23_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_2_relu (Activati  (None, 7, 7, 256)   0           ['conv4_block23_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block22_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block23_3_conv (Conv2D)  (None, 7, 7, 1024)   263168      ['conv4_block23_2_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_out (Add)        (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv4_block23_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block23_out[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 200)          409800      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,036,360\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 42,626,560\n",
      "__________________________________________________________________________________________________\n",
      "InceptionV3\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 73, 73, 64)  0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_4[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 200)          409800      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,212,584\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for analysis propurses\n",
    "print(\"VGG16\")\n",
    "vgg16_model.summary()\n",
    "print(\"VGG19\")\n",
    "vgg19_model.summary()\n",
    "print(\"Resnet50\")\n",
    "resnet50v2_model.summary()\n",
    "print(\"Resnet100\")\n",
    "resnet101V2_model.summary()\n",
    "print(\"InceptionV3\")\n",
    "inceptionv3_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
