{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68330ff4-6406-4270-ac18-e5dfe76052c3",
   "metadata": {},
   "source": [
    "Here to try to finetune the CNN networks with my own PC (single 1080ti) on the tiny imagenet dataset\n",
    "First we download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12172c2e-2412-42e0-a138-370a8482fc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data','tiny-imagenet-200.zip')):\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','tiny-imagenet-200.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'tiny-imagenet-200')):\n",
    "    with zipfile.ZipFile(os.path.join('data','tiny-imagenet-200.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd060f-b1e3-4b9f-837e-125ecec90183",
   "metadata": {},
   "source": [
    "Chekcing the setups and importing related packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45be974c-80fa-42a8-a9ed-486c7fd29068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import requests\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AvgPool2D, Dense, Concatenate, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed, using my birth year\n",
    "random_seed = 1997\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420449b-32a0-43ec-b7d2-432233a67c61",
   "metadata": {},
   "source": [
    "Functions for parsing teh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d48f2b-c04c-43b0-85ed-160f59f34d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n",
      "Found 90000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n",
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_test_labels_df(test_labels_path):\n",
    "    \"\"\" Reading the test data labels for all files in the test set as a data frame \"\"\"\n",
    "    test_df = pd.read_csv(test_labels_path, sep='\\t', index_col=None, header=None)\n",
    "    test_df = test_df.iloc[:,[0,1]].rename({0:\"filename\", 1:\"class\"}, axis=1)\n",
    "    return test_df\n",
    "\n",
    "def get_train_valid_test_data_generators(batch_size, target_size):\n",
    "    \"\"\" Get the training/validation/testing data generators \"\"\"\n",
    "    \n",
    "    # Defining a data-augmenting image data generator and a standard image data generator\n",
    "    image_gen_aug = ImageDataGenerator(\n",
    "        samplewise_center=False, rotation_range=30, width_shift_range=0.2,\n",
    "        height_shift_range=0.2, brightness_range=(0.5,1.5), shear_range=5, \n",
    "        zoom_range=0.2, horizontal_flip=True, fill_mode='constant', cval=127.5, \n",
    "        validation_split=0.1\n",
    "    )\n",
    "    image_gen = ImageDataGenerator(samplewise_center=False)\n",
    "    \n",
    "    # Define a training data generator\n",
    "    partial_flow_func = partial(\n",
    "        image_gen_aug.flow_from_directory, \n",
    "        directory=os.path.join('data','tiny-imagenet-200', 'train'), \n",
    "        target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, \n",
    "        shuffle=True, seed=random_seed)\n",
    "    \n",
    "    # Get the training data subset\n",
    "    train_gen = partial_flow_func(subset='training')\n",
    "    # Get the validation data subset\n",
    "    valid_gen = partial_flow_func(subset='validation')    \n",
    "\n",
    "    # Defining the test data generator\n",
    "    test_df = get_test_labels_df(os.path.join('data','tiny-imagenet-200',  'val', 'val_annotations.txt'))\n",
    "    test_gen = image_gen.flow_from_dataframe(\n",
    "        test_df, directory=os.path.join('data','tiny-imagenet-200',  'val', 'images'), target_size=target_size, classes=None,\n",
    "        class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (224,224)\n",
    "# Getting the train,valid, test data generators\n",
    "train_gen, valid_gen, test_gen = get_train_valid_test_data_generators(batch_size, target_size)\n",
    "# Modifying the data generators to fit the model targets\n",
    "train_gen_inceptionV3, valid_gen_inceptionV3, test_gen_inceptionV3 = get_train_valid_test_data_generators(batch_size,(299,299))\n",
    "\n",
    "with open(os.path.join('data','class_indices'), 'wb') as f:\n",
    "    pickle.dump(train_gen.class_indices, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2812bd9-6320-4ae1-b478-13f7c3c5c4f6",
   "metadata": {},
   "source": [
    "The models we are finetuning are:\n",
    "1. VGG family: 16 and 19\n",
    "2. ResNet family: 50v2 and 101 v2\n",
    "3. InceptionV3\n",
    "From a preliminary run of the code, I expect difficulty with InceptionV3. My GPU has limited (11GB) memory space and it's likely to eat it all up.\n",
    "None the less, all network are trained with 15 epoch, then 50 epochs, then 100 epoch, or till an error forces a stop.\n",
    "Accuracy and loss score are either calculated if the training is completed, or taken using the last finished epoch's value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7466a4-7a05-4e71-bdb4-dcb1ab0f79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19,ResNet50V2,InceptionV3,VGG16,ResNet101V2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def create_inceptionv3_model(input_shape=(299, 299, 3), num_classes=200):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "inceptionv3_model = create_inceptionv3_model()\n",
    "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_resnet50v2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet50v2_model = create_resnet50v2_model()\n",
    "resnet50v2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_vgg19_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg19_model = create_vgg19_model()\n",
    "vgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def create_ResNet101V2_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = ResNet101V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "resnet101V2_model = create_ResNet101V2_model()\n",
    "resnet101V2_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "def create_vgg16_model(input_shape=(224, 224, 3), num_classes=200):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "vgg16_model = create_vgg16_model()\n",
    "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#vgg16_model.summary()\n",
    "#resnet101V2_model.summary()\n",
    "#vgg19_model.summary()\n",
    "#resnet50v2_model.summary()\n",
    "#inceptionv3_model.summary()\n",
    "\n",
    "models = [(vgg16_model,\"vgg_16_\"),(vgg19_model,\"vgg_19_\"),(resnet50v2_model,\"resnet_50_\"),(resnet101V2_model,\"resnet_101_\"),(inceptionv3_model,\"inception_v3\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aba5f5-4619-4880-861f-2218965ff322",
   "metadata": {},
   "source": [
    "Helper functions for early stopping and changing learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa9a727-56e5-462a-a2a3-352af3aeb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=25)\n",
    "lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'\n",
    ")\n",
    "def get_steps_per_epoch(n_data, batch_size):\n",
    "    \"\"\" Given the data size and batch size, gives the number of steps to travers the full dataset \"\"\"\n",
    "    if n_data%batch_size==0:\n",
    "        return int(n_data/batch_size)\n",
    "    else:\n",
    "        return int(n_data*1.0/batch_size)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c9987-692b-4713-bd19-016d7df20679",
   "metadata": {},
   "source": [
    "Function for finetuning the models, and getting the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179bf772-6b5d-42e4-8467-e2b03150eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model,name,n_epochs):\n",
    "    print(\"Training model:\",name[:-1])\n",
    "    history = model.fit(\n",
    "        train_gen, validation_data=valid_gen, \n",
    "        steps_per_epoch=get_steps_per_epoch(int(0.9*(500*200)), batch_size), \n",
    "        validation_steps=get_steps_per_epoch(int(0.1*(500*200)), batch_size),\n",
    "        epochs=n_epochs, callbacks=[es_callback, lr_callback]\n",
    "    )\n",
    "    model_path = name+str(n_epochs)+'.h5'\n",
    "    print(\"Saving model to:\",model_path)\n",
    "    if not os.path.exists('models'):\n",
    "        os.mkdir(\"models\")\n",
    "    model.save(os.path.join('models',model_path))\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating model:\",name[:-1])\n",
    "    test_res = model.evaluate(test_gen, steps=get_steps_per_epoch(500*50, batch_size))\n",
    "    \n",
    "    # Print the results as a dictionary {<metric name>: <value>}\n",
    "    test_res_dict = dict(zip(model.metrics_names, test_res))\n",
    "    print(test_res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52745523-093b-461f-bf84-8666a8b303d0",
   "metadata": {},
   "source": [
    "Try for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0292c3-f206-4079-a047-c7ba5ec4f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_16\n",
      "Epoch 1/15\n",
      "2813/2813 [==============================] - 442s 156ms/step - loss: 97.8764 - accuracy: 0.1383 - val_loss: 112.4329 - val_accuracy: 0.1832 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2813/2813 [==============================] - 461s 164ms/step - loss: 116.5817 - accuracy: 0.2059 - val_loss: 131.1448 - val_accuracy: 0.2017 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 125.0914 - accuracy: 0.2297 - val_loss: 135.1010 - val_accuracy: 0.2276 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 129.5921 - accuracy: 0.2483 - val_loss: 146.8262 - val_accuracy: 0.2230 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2813/2813 [==============================] - 419s 149ms/step - loss: 133.8336 - accuracy: 0.2599 - val_loss: 149.8744 - val_accuracy: 0.2436 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 137.4862 - accuracy: 0.2699\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 137.4862 - accuracy: 0.2699 - val_loss: 159.5892 - val_accuracy: 0.2408 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 111.8882 - accuracy: 0.3185 - val_loss: 130.5478 - val_accuracy: 0.2733 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "2813/2813 [==============================] - 418s 149ms/step - loss: 101.3769 - accuracy: 0.3314 - val_loss: 121.7607 - val_accuracy: 0.2844 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 96.1708 - accuracy: 0.3417 - val_loss: 119.0675 - val_accuracy: 0.2828 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 92.1638 - accuracy: 0.3442 - val_loss: 113.3819 - val_accuracy: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "2813/2813 [==============================] - 419s 149ms/step - loss: 88.9398 - accuracy: 0.3478 - val_loss: 110.3519 - val_accuracy: 0.2882 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 85.9305 - accuracy: 0.3512 - val_loss: 110.6425 - val_accuracy: 0.2831 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 83.4589 - accuracy: 0.3543 - val_loss: 105.6935 - val_accuracy: 0.2882 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 81.3715 - accuracy: 0.3597 - val_loss: 104.3330 - val_accuracy: 0.2924 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 78.9483 - accuracy: 0.3623 - val_loss: 101.1403 - val_accuracy: 0.2910 - lr: 1.0000e-04\n",
      "Saving model to: vgg_16_15.h5\n",
      "Evaluating model: vgg_16\n",
      "312/782 [==========>...................] - ETA: 28s - loss: 119.7637 - accuracy: 0.3009WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 119.8349 - accuracy: 0.3007\n",
      "{'loss': 119.83492279052734, 'accuracy': 0.30070000886917114}\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "train_test_model(vgg16_model,\"vgg_16_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1971625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_19\n",
      "Epoch 1/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 89.9761 - accuracy: 0.1363 - val_loss: 105.4751 - val_accuracy: 0.1757 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 106.7084 - accuracy: 0.2005 - val_loss: 118.8325 - val_accuracy: 0.2022 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 113.7364 - accuracy: 0.2267 - val_loss: 127.1895 - val_accuracy: 0.2116 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 118.7862 - accuracy: 0.2430 - val_loss: 133.5663 - val_accuracy: 0.2224 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 122.4207 - accuracy: 0.2540 - val_loss: 139.5491 - val_accuracy: 0.2309 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 125.5478 - accuracy: 0.2631\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 125.5478 - accuracy: 0.2631 - val_loss: 147.9496 - val_accuracy: 0.2287 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 100.9857 - accuracy: 0.3128 - val_loss: 116.1636 - val_accuracy: 0.2691 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 92.1829 - accuracy: 0.3261 - val_loss: 110.9808 - val_accuracy: 0.2742 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 86.3248 - accuracy: 0.3368 - val_loss: 106.4311 - val_accuracy: 0.2791 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 83.3154 - accuracy: 0.3392 - val_loss: 103.1966 - val_accuracy: 0.2759 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 80.1046 - accuracy: 0.3413 - val_loss: 99.9213 - val_accuracy: 0.2830 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 77.0283 - accuracy: 0.3470 - val_loss: 97.1584 - val_accuracy: 0.2869 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 74.8490 - accuracy: 0.3478 - val_loss: 94.7769 - val_accuracy: 0.2855 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 72.4449 - accuracy: 0.3539 - val_loss: 92.9728 - val_accuracy: 0.2837 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 70.8422 - accuracy: 0.3548 - val_loss: 91.2301 - val_accuracy: 0.2890 - lr: 1.0000e-04\n",
      "Saving model to: vgg_19_15.h5\n",
      "Evaluating model: vgg_19\n",
      "312/782 [==========>...................] - ETA: 34s - loss: 112.2108 - accuracy: 0.3014WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 112.1886 - accuracy: 0.3014\n",
      "{'loss': 112.18859100341797, 'accuracy': 0.30140000581741333}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(vgg19_model,\"vgg_19_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3d0df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_50\n",
      "Epoch 1/15\n",
      "2813/2813 [==============================] - 427s 151ms/step - loss: 73.3253 - accuracy: 0.0219 - val_loss: 71.3381 - val_accuracy: 0.0264 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 71.4292 - accuracy: 0.0312 - val_loss: 72.6323 - val_accuracy: 0.0264 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 69.1710 - accuracy: 0.0358 - val_loss: 72.6860 - val_accuracy: 0.0305 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 68.9773 - accuracy: 0.0384 - val_loss: 69.1739 - val_accuracy: 0.0322 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 68.9473 - accuracy: 0.0402 - val_loss: 76.7712 - val_accuracy: 0.0370 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 67.9721 - accuracy: 0.0419 - val_loss: 65.8077 - val_accuracy: 0.0397 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 67.8292 - accuracy: 0.0442 - val_loss: 60.4096 - val_accuracy: 0.0510 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 67.7524 - accuracy: 0.0455 - val_loss: 59.8654 - val_accuracy: 0.0423 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 66.6372 - accuracy: 0.0459 - val_loss: 59.5909 - val_accuracy: 0.0519 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 67.4885 - accuracy: 0.0481 - val_loss: 76.7285 - val_accuracy: 0.0376 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 66.8949 - accuracy: 0.0485 - val_loss: 66.9472 - val_accuracy: 0.0434 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 65.9097 - accuracy: 0.0488 - val_loss: 61.2331 - val_accuracy: 0.0437 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 66.6932 - accuracy: 0.0483 - val_loss: 65.9582 - val_accuracy: 0.0446 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 66.0781 - accuracy: 0.0508 - val_loss: 58.4695 - val_accuracy: 0.0461 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 66.2216 - accuracy: 0.0509 - val_loss: 70.2044 - val_accuracy: 0.0416 - lr: 0.0010\n",
      "Saving model to: resnet_50_15.h5\n",
      "Evaluating model: resnet_50\n",
      "313/782 [===========>..................] - ETA: 23s - loss: 76.7331 - accuracy: 0.0534WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 76.7331 - accuracy: 0.0534\n",
      "{'loss': 76.73310089111328, 'accuracy': 0.05339999869465828}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet50v2_model,\"resnet_50_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ecd3067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_101\n",
      "Epoch 1/15\n",
      "2813/2813 [==============================] - 428s 151ms/step - loss: 182.6077 - accuracy: 0.0156 - val_loss: 148.2959 - val_accuracy: 0.0214 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 178.1198 - accuracy: 0.0212 - val_loss: 169.0116 - val_accuracy: 0.0216 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 176.5454 - accuracy: 0.0242 - val_loss: 171.3275 - val_accuracy: 0.0324 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 176.1174 - accuracy: 0.0261 - val_loss: 192.0960 - val_accuracy: 0.0219 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 171.7699 - accuracy: 0.0276 - val_loss: 177.9083 - val_accuracy: 0.0206 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 173.0019 - accuracy: 0.0293\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 173.0019 - accuracy: 0.0293 - val_loss: 171.4178 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 27.3130 - accuracy: 0.0689 - val_loss: 20.4447 - val_accuracy: 0.0715 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 20.8872 - accuracy: 0.0646 - val_loss: 20.7918 - val_accuracy: 0.0621 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 20.1866 - accuracy: 0.0652 - val_loss: 20.5115 - val_accuracy: 0.0585 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 19.5384 - accuracy: 0.0636 - val_loss: 19.1265 - val_accuracy: 0.0629 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 19.0760 - accuracy: 0.0616 - val_loss: 19.5879 - val_accuracy: 0.0579 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 18.6220 - accuracy: 0.0617 - val_loss: 20.7402 - val_accuracy: 0.0551 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 18.3191 - accuracy: 0.0619 - val_loss: 18.9451 - val_accuracy: 0.0573 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 18.0108 - accuracy: 0.0620 - val_loss: 19.2518 - val_accuracy: 0.0562 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 17.7855 - accuracy: 0.0602 - val_loss: 18.2379 - val_accuracy: 0.0561 - lr: 1.0000e-04\n",
      "Saving model to: resnet_101_15.h5\n",
      "Evaluating model: resnet_101\n",
      "312/782 [==========>...................] - ETA: 39s - loss: 19.4851 - accuracy: 0.0686WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 27s 34ms/step - loss: 19.4823 - accuracy: 0.0685\n",
      "{'loss': 19.482315063476562, 'accuracy': 0.06849999725818634}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet101V2_model,\"resnet_101_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6faf3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: inception_v\n",
      "Epoch 1/15\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 30.4384 - accuracy: 0.0157 - val_loss: 29.3523 - val_accuracy: 0.0182 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 28.9521 - accuracy: 0.0190 - val_loss: 31.1039 - val_accuracy: 0.0202 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 28.4059 - accuracy: 0.0209 - val_loss: 29.9128 - val_accuracy: 0.0191 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 28.2938 - accuracy: 0.0219 - val_loss: 29.6297 - val_accuracy: 0.0239 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 28.1465 - accuracy: 0.0233 - val_loss: 28.7201 - val_accuracy: 0.0213 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 28.5179 - accuracy: 0.0233 - val_loss: 30.9236 - val_accuracy: 0.0259 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 28.1914 - accuracy: 0.0242 - val_loss: 27.6188 - val_accuracy: 0.0240 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 28.1472 - accuracy: 0.0242 - val_loss: 28.0350 - val_accuracy: 0.0244 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 27.9525 - accuracy: 0.0256 - val_loss: 29.8123 - val_accuracy: 0.0255 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 28.0513 - accuracy: 0.0253 - val_loss: 28.6724 - val_accuracy: 0.0240 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 28.2570 - accuracy: 0.0250 - val_loss: 28.1630 - val_accuracy: 0.0292 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 28.3465 - accuracy: 0.0249 - val_loss: 27.0982 - val_accuracy: 0.0209 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 28.1784 - accuracy: 0.0262 - val_loss: 28.9651 - val_accuracy: 0.0229 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 27.9225 - accuracy: 0.0258 - val_loss: 26.3989 - val_accuracy: 0.0320 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 28.1284 - accuracy: 0.0261 - val_loss: 28.5494 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Saving model to: inception_v315.h5\n",
      "Evaluating model: inception_v\n",
      "313/782 [===========>..................] - ETA: 17s - loss: 31.0757 - accuracy: 0.0308WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 31.0757 - accuracy: 0.0308\n",
      "{'loss': 31.07565689086914, 'accuracy': 0.030799999833106995}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(inceptionv3_model,\"inception_v3\",n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50323fac",
   "metadata": {},
   "source": [
    "Try for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83537473-ce05-437c-97d5-a1fc5532862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_16\n",
      "Epoch 1/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 77.3275 - accuracy: 0.3620 - val_loss: 99.6394 - val_accuracy: 0.2962 - lr: 1.0000e-04\n",
      "Epoch 2/35\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 74.9489 - accuracy: 0.3658 - val_loss: 99.6033 - val_accuracy: 0.2966 - lr: 1.0000e-04\n",
      "Epoch 3/35\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 73.5450 - accuracy: 0.3667 - val_loss: 96.4985 - val_accuracy: 0.2910 - lr: 1.0000e-04\n",
      "Epoch 4/35\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 72.1212 - accuracy: 0.3685 - val_loss: 95.4666 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 5/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 70.5878 - accuracy: 0.3695 - val_loss: 93.9825 - val_accuracy: 0.2982 - lr: 1.0000e-04\n",
      "Epoch 6/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 69.3428 - accuracy: 0.3716 - val_loss: 93.0719 - val_accuracy: 0.2935 - lr: 1.0000e-04\n",
      "Epoch 7/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 68.5144 - accuracy: 0.3713 - val_loss: 91.3948 - val_accuracy: 0.2999 - lr: 1.0000e-04\n",
      "Epoch 8/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 67.0813 - accuracy: 0.3748 - val_loss: 89.7010 - val_accuracy: 0.3029 - lr: 1.0000e-04\n",
      "Epoch 9/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 65.9810 - accuracy: 0.3752 - val_loss: 89.0972 - val_accuracy: 0.2962 - lr: 1.0000e-04\n",
      "Epoch 10/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 64.7751 - accuracy: 0.3777 - val_loss: 88.1757 - val_accuracy: 0.2976 - lr: 1.0000e-04\n",
      "Epoch 11/35\n",
      "2813/2813 [==============================] - 419s 149ms/step - loss: 63.8193 - accuracy: 0.3775 - val_loss: 85.7740 - val_accuracy: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 12/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 63.1041 - accuracy: 0.3779 - val_loss: 85.8776 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
      "Epoch 13/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 61.8380 - accuracy: 0.3788 - val_loss: 84.7265 - val_accuracy: 0.2964 - lr: 1.0000e-04\n",
      "Epoch 14/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 61.3033 - accuracy: 0.3796 - val_loss: 83.7820 - val_accuracy: 0.3003 - lr: 1.0000e-04\n",
      "Epoch 15/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 60.1549 - accuracy: 0.3825 - val_loss: 83.2781 - val_accuracy: 0.2995 - lr: 1.0000e-04\n",
      "Epoch 16/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 59.1682 - accuracy: 0.3817 - val_loss: 81.8843 - val_accuracy: 0.3059 - lr: 1.0000e-04\n",
      "Epoch 17/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 58.7020 - accuracy: 0.3824 - val_loss: 80.9105 - val_accuracy: 0.3052 - lr: 1.0000e-04\n",
      "Epoch 18/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 57.7640 - accuracy: 0.3836 - val_loss: 80.2811 - val_accuracy: 0.3062 - lr: 1.0000e-04\n",
      "Epoch 19/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 56.8684 - accuracy: 0.3839 - val_loss: 79.0624 - val_accuracy: 0.3083 - lr: 1.0000e-04\n",
      "Epoch 20/35\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 56.2097 - accuracy: 0.3847 - val_loss: 79.3129 - val_accuracy: 0.2988 - lr: 1.0000e-04\n",
      "Epoch 21/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 55.8414 - accuracy: 0.3855 - val_loss: 78.3392 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 22/35\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 55.1423 - accuracy: 0.3848 - val_loss: 77.2423 - val_accuracy: 0.2985 - lr: 1.0000e-04\n",
      "Epoch 23/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 54.2055 - accuracy: 0.3866 - val_loss: 76.8208 - val_accuracy: 0.2958 - lr: 1.0000e-04\n",
      "Epoch 24/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 53.6554 - accuracy: 0.3887 - val_loss: 76.8772 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
      "Epoch 25/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 53.1729 - accuracy: 0.3889 - val_loss: 74.3758 - val_accuracy: 0.3070 - lr: 1.0000e-04\n",
      "Epoch 26/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 52.3812 - accuracy: 0.3899 - val_loss: 75.0507 - val_accuracy: 0.3018 - lr: 1.0000e-04\n",
      "Epoch 27/35\n",
      "2813/2813 [==============================] - 420s 149ms/step - loss: 51.7351 - accuracy: 0.3880 - val_loss: 74.1409 - val_accuracy: 0.3026 - lr: 1.0000e-04\n",
      "Epoch 28/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 51.1982 - accuracy: 0.3893 - val_loss: 74.4342 - val_accuracy: 0.2987 - lr: 1.0000e-04\n",
      "Epoch 29/35\n",
      "2813/2813 [==============================] - 421s 150ms/step - loss: 50.6112 - accuracy: 0.3918 - val_loss: 71.5302 - val_accuracy: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 30/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 50.4022 - accuracy: 0.3894 - val_loss: 72.0691 - val_accuracy: 0.2996 - lr: 1.0000e-04\n",
      "Epoch 31/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 49.7970 - accuracy: 0.3904 - val_loss: 72.3185 - val_accuracy: 0.2999 - lr: 1.0000e-04\n",
      "Epoch 32/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 49.3923 - accuracy: 0.3900 - val_loss: 70.9594 - val_accuracy: 0.2977 - lr: 1.0000e-04\n",
      "Epoch 33/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 48.3333 - accuracy: 0.3918 - val_loss: 70.1189 - val_accuracy: 0.3016 - lr: 1.0000e-04\n",
      "Epoch 34/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 48.0577 - accuracy: 0.3939 - val_loss: 70.7411 - val_accuracy: 0.2972 - lr: 1.0000e-04\n",
      "Epoch 35/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 47.8550 - accuracy: 0.3919 - val_loss: 68.6003 - val_accuracy: 0.3024 - lr: 1.0000e-04\n",
      "Saving model to: vgg_16_35.h5\n",
      "Evaluating model: vgg_16\n",
      "312/782 [==========>...................] - ETA: 28s - loss: 81.8290 - accuracy: 0.3138WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 81.9144 - accuracy: 0.3135\n",
      "{'loss': 81.91439819335938, 'accuracy': 0.31349998712539673}\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 35\n",
    "# the for loop is prone to OOM errors\n",
    "# calling training for each model individually\n",
    "# for (model, name) in models:\n",
    "#     print(\"Training model:\",name[:-1])\n",
    "#     train_test_model(model,name,n_epochs)\n",
    "train_test_model(vgg16_model,\"vgg_16_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b624c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_19\n",
      "Epoch 1/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 68.9714 - accuracy: 0.3562 - val_loss: 89.2253 - val_accuracy: 0.2815 - lr: 1.0000e-04\n",
      "Epoch 2/35\n",
      "2813/2813 [==============================] - 422s 150ms/step - loss: 67.5415 - accuracy: 0.3574 - val_loss: 87.9904 - val_accuracy: 0.2918 - lr: 1.0000e-04\n",
      "Epoch 3/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 65.9360 - accuracy: 0.3585 - val_loss: 86.4893 - val_accuracy: 0.2921 - lr: 1.0000e-04\n",
      "Epoch 4/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 65.0243 - accuracy: 0.3600 - val_loss: 84.3622 - val_accuracy: 0.2904 - lr: 1.0000e-04\n",
      "Epoch 5/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 63.8752 - accuracy: 0.3622 - val_loss: 83.1889 - val_accuracy: 0.2909 - lr: 1.0000e-04\n",
      "Epoch 6/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 62.2325 - accuracy: 0.3626 - val_loss: 82.4855 - val_accuracy: 0.2904 - lr: 1.0000e-04\n",
      "Epoch 7/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 61.1416 - accuracy: 0.3655 - val_loss: 79.3720 - val_accuracy: 0.2912 - lr: 1.0000e-04\n",
      "Epoch 8/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 60.2048 - accuracy: 0.3654 - val_loss: 79.3458 - val_accuracy: 0.2980 - lr: 1.0000e-04\n",
      "Epoch 9/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 58.8828 - accuracy: 0.3675 - val_loss: 79.3124 - val_accuracy: 0.2949 - lr: 1.0000e-04\n",
      "Epoch 10/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 58.0075 - accuracy: 0.3679 - val_loss: 77.0368 - val_accuracy: 0.2970 - lr: 1.0000e-04\n",
      "Epoch 11/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 57.0476 - accuracy: 0.3685 - val_loss: 77.3066 - val_accuracy: 0.2865 - lr: 1.0000e-04\n",
      "Epoch 12/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 56.4489 - accuracy: 0.3698 - val_loss: 77.5020 - val_accuracy: 0.2884 - lr: 1.0000e-04\n",
      "Epoch 13/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 55.3442 - accuracy: 0.3709 - val_loss: 75.0020 - val_accuracy: 0.2959 - lr: 1.0000e-04\n",
      "Epoch 14/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 54.5535 - accuracy: 0.3717 - val_loss: 74.2951 - val_accuracy: 0.2949 - lr: 1.0000e-04\n",
      "Epoch 15/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 54.0098 - accuracy: 0.3709 - val_loss: 73.7674 - val_accuracy: 0.2933 - lr: 1.0000e-04\n",
      "Epoch 16/35\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 53.1878 - accuracy: 0.3732 - val_loss: 72.8297 - val_accuracy: 0.2970 - lr: 1.0000e-04\n",
      "Epoch 17/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 52.2621 - accuracy: 0.3723 - val_loss: 71.9175 - val_accuracy: 0.2909 - lr: 1.0000e-04\n",
      "Epoch 18/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 51.3553 - accuracy: 0.3750 - val_loss: 70.5046 - val_accuracy: 0.2914 - lr: 1.0000e-04\n",
      "Epoch 19/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 50.8268 - accuracy: 0.3758 - val_loss: 70.7098 - val_accuracy: 0.2956 - lr: 1.0000e-04\n",
      "Epoch 20/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 49.9607 - accuracy: 0.3765 - val_loss: 70.1320 - val_accuracy: 0.2916 - lr: 1.0000e-04\n",
      "Epoch 21/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 49.3894 - accuracy: 0.3786 - val_loss: 68.4590 - val_accuracy: 0.2957 - lr: 1.0000e-04\n",
      "Epoch 22/35\n",
      "2813/2813 [==============================] - 423s 150ms/step - loss: 49.0979 - accuracy: 0.3781 - val_loss: 69.4734 - val_accuracy: 0.2885 - lr: 1.0000e-04\n",
      "Epoch 23/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 48.4651 - accuracy: 0.3780 - val_loss: 67.6168 - val_accuracy: 0.2942 - lr: 1.0000e-04\n",
      "Epoch 24/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 48.0865 - accuracy: 0.3770 - val_loss: 68.0462 - val_accuracy: 0.2844 - lr: 1.0000e-04\n",
      "Epoch 25/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 47.2266 - accuracy: 0.3787 - val_loss: 66.5932 - val_accuracy: 0.2972 - lr: 1.0000e-04\n",
      "Epoch 26/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 46.8397 - accuracy: 0.3810 - val_loss: 65.6681 - val_accuracy: 0.3002 - lr: 1.0000e-04\n",
      "Epoch 27/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 46.1822 - accuracy: 0.3826 - val_loss: 64.8059 - val_accuracy: 0.2916 - lr: 1.0000e-04\n",
      "Epoch 28/35\n",
      "2813/2813 [==============================] - 450s 160ms/step - loss: 45.8319 - accuracy: 0.3800 - val_loss: 65.6885 - val_accuracy: 0.2921 - lr: 1.0000e-04\n",
      "Epoch 29/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 45.0778 - accuracy: 0.3803 - val_loss: 63.2670 - val_accuracy: 0.2994 - lr: 1.0000e-04\n",
      "Epoch 30/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 44.8802 - accuracy: 0.3791 - val_loss: 64.1131 - val_accuracy: 0.2939 - lr: 1.0000e-04\n",
      "Epoch 31/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 44.4304 - accuracy: 0.3803 - val_loss: 62.8667 - val_accuracy: 0.2935 - lr: 1.0000e-04\n",
      "Epoch 32/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 43.7426 - accuracy: 0.3826 - val_loss: 62.5186 - val_accuracy: 0.2931 - lr: 1.0000e-04\n",
      "Epoch 33/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 43.2304 - accuracy: 0.3818 - val_loss: 62.4224 - val_accuracy: 0.2940 - lr: 1.0000e-04\n",
      "Epoch 34/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 42.8270 - accuracy: 0.3855 - val_loss: 61.1440 - val_accuracy: 0.2943 - lr: 1.0000e-04\n",
      "Epoch 35/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 42.5390 - accuracy: 0.3824 - val_loss: 60.6589 - val_accuracy: 0.2863 - lr: 1.0000e-04\n",
      "Saving model to: vgg_19_35.h5\n",
      "Evaluating model: vgg_19\n",
      "312/782 [==========>...................] - ETA: 33s - loss: 75.9333 - accuracy: 0.3045WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 75.9145 - accuracy: 0.3045\n",
      "{'loss': 75.91445922851562, 'accuracy': 0.304500013589859}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(vgg19_model,\"vgg_19_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb240ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_50\n",
      "Epoch 1/35\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 66.5302 - accuracy: 0.0509 - val_loss: 58.4711 - val_accuracy: 0.0515 - lr: 0.0010\n",
      "Epoch 2/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 65.4454 - accuracy: 0.0523 - val_loss: 68.7339 - val_accuracy: 0.0433 - lr: 0.0010\n",
      "Epoch 3/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 66.3366 - accuracy: 0.0530 - val_loss: 72.9455 - val_accuracy: 0.0516 - lr: 0.0010\n",
      "Epoch 4/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 65.7546 - accuracy: 0.0550 - val_loss: 57.0018 - val_accuracy: 0.0562 - lr: 0.0010\n",
      "Epoch 5/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 65.7521 - accuracy: 0.0547 - val_loss: 73.8647 - val_accuracy: 0.0455 - lr: 0.0010\n",
      "Epoch 6/35\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 65.7521 - accuracy: 0.0548 - val_loss: 70.9989 - val_accuracy: 0.0444 - lr: 0.0010\n",
      "Epoch 7/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 65.6910 - accuracy: 0.0548 - val_loss: 65.2759 - val_accuracy: 0.0539 - lr: 0.0010\n",
      "Epoch 8/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 65.4866 - accuracy: 0.0550 - val_loss: 68.8793 - val_accuracy: 0.0548 - lr: 0.0010\n",
      "Epoch 9/35\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 66.2983 - accuracy: 0.0570\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 66.2983 - accuracy: 0.0570 - val_loss: 67.0731 - val_accuracy: 0.0538 - lr: 0.0010\n",
      "Epoch 10/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 15.9867 - accuracy: 0.1234 - val_loss: 15.0685 - val_accuracy: 0.1094 - lr: 1.0000e-04\n",
      "Epoch 11/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 13.6853 - accuracy: 0.1218 - val_loss: 14.3910 - val_accuracy: 0.1153 - lr: 1.0000e-04\n",
      "Epoch 12/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 13.1957 - accuracy: 0.1215 - val_loss: 14.7960 - val_accuracy: 0.0994 - lr: 1.0000e-04\n",
      "Epoch 13/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 12.8569 - accuracy: 0.1190 - val_loss: 13.6806 - val_accuracy: 0.1065 - lr: 1.0000e-04\n",
      "Epoch 14/35\n",
      "2813/2813 [==============================] - 424s 151ms/step - loss: 12.5785 - accuracy: 0.1191 - val_loss: 13.3716 - val_accuracy: 0.1010 - lr: 1.0000e-04\n",
      "Epoch 15/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 12.2709 - accuracy: 0.1183 - val_loss: 12.7941 - val_accuracy: 0.1047 - lr: 1.0000e-04\n",
      "Epoch 16/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 12.0804 - accuracy: 0.1187 - val_loss: 12.8495 - val_accuracy: 0.0995 - lr: 1.0000e-04\n",
      "Epoch 17/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 11.9314 - accuracy: 0.1163 - val_loss: 13.5496 - val_accuracy: 0.0948 - lr: 1.0000e-04\n",
      "Epoch 18/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 11.7574 - accuracy: 0.1174 - val_loss: 12.5821 - val_accuracy: 0.0986 - lr: 1.0000e-04\n",
      "Epoch 19/35\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 11.6406 - accuracy: 0.1158 - val_loss: 12.3853 - val_accuracy: 0.0983 - lr: 1.0000e-04\n",
      "Epoch 20/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 11.4199 - accuracy: 0.1165 - val_loss: 12.3308 - val_accuracy: 0.0967 - lr: 1.0000e-04\n",
      "Epoch 21/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 11.2785 - accuracy: 0.1159 - val_loss: 12.3736 - val_accuracy: 0.0996 - lr: 1.0000e-04\n",
      "Epoch 22/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 11.2101 - accuracy: 0.1148 - val_loss: 11.9323 - val_accuracy: 0.0986 - lr: 1.0000e-04\n",
      "Epoch 23/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 11.0585 - accuracy: 0.1174 - val_loss: 11.7382 - val_accuracy: 0.0972 - lr: 1.0000e-04\n",
      "Epoch 24/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 10.9092 - accuracy: 0.1170 - val_loss: 11.5811 - val_accuracy: 0.0983 - lr: 1.0000e-04\n",
      "Epoch 25/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 10.8687 - accuracy: 0.1142 - val_loss: 12.0033 - val_accuracy: 0.0981 - lr: 1.0000e-04\n",
      "Epoch 26/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 10.7689 - accuracy: 0.1138 - val_loss: 11.4667 - val_accuracy: 0.0984 - lr: 1.0000e-04\n",
      "Epoch 27/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.6638 - accuracy: 0.1144 - val_loss: 11.4199 - val_accuracy: 0.1029 - lr: 1.0000e-04\n",
      "Epoch 28/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.5544 - accuracy: 0.1156 - val_loss: 11.1125 - val_accuracy: 0.0901 - lr: 1.0000e-04\n",
      "Epoch 29/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 10.4638 - accuracy: 0.1128 - val_loss: 11.4931 - val_accuracy: 0.0902 - lr: 1.0000e-04\n",
      "Epoch 30/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.4378 - accuracy: 0.1134 - val_loss: 11.6945 - val_accuracy: 0.0924 - lr: 1.0000e-04\n",
      "Epoch 31/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.3612 - accuracy: 0.1121 - val_loss: 11.0308 - val_accuracy: 0.0961 - lr: 1.0000e-04\n",
      "Epoch 32/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 10.2341 - accuracy: 0.1109 - val_loss: 10.9683 - val_accuracy: 0.0946 - lr: 1.0000e-04\n",
      "Epoch 33/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.1521 - accuracy: 0.1136 - val_loss: 11.0716 - val_accuracy: 0.0978 - lr: 1.0000e-04\n",
      "Epoch 34/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.0375 - accuracy: 0.1117 - val_loss: 11.0921 - val_accuracy: 0.0944 - lr: 1.0000e-04\n",
      "Epoch 35/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 10.0297 - accuracy: 0.1114 - val_loss: 10.2720 - val_accuracy: 0.1000 - lr: 1.0000e-04\n",
      "Saving model to: resnet_50_35.h5\n",
      "Evaluating model: resnet_50\n",
      "313/782 [===========>..................] - ETA: 22s - loss: 11.9955 - accuracy: 0.1190WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 11.9955 - accuracy: 0.1190\n",
      "{'loss': 11.995530128479004, 'accuracy': 0.11900000274181366}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet50v2_model,\"resnet_50_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "927a2ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_101\n",
      "Epoch 1/35\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.8578 - accuracy: 0.0837 - val_loss: 8.1302 - val_accuracy: 0.0787 - lr: 1.0000e-05\n",
      "Epoch 2/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 7.8141 - accuracy: 0.0836 - val_loss: 8.2030 - val_accuracy: 0.0766 - lr: 1.0000e-05\n",
      "Epoch 3/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 7.8003 - accuracy: 0.0845 - val_loss: 8.2044 - val_accuracy: 0.0774 - lr: 1.0000e-05\n",
      "Epoch 4/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 7.7900 - accuracy: 0.0842 - val_loss: 8.2821 - val_accuracy: 0.0744 - lr: 1.0000e-05\n",
      "Epoch 5/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.7505 - accuracy: 0.0827 - val_loss: 8.1566 - val_accuracy: 0.0773 - lr: 1.0000e-05\n",
      "Epoch 6/35\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 7.7357 - accuracy: 0.0844\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.7357 - accuracy: 0.0844 - val_loss: 8.2206 - val_accuracy: 0.0789 - lr: 1.0000e-05\n",
      "Epoch 7/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.1742 - accuracy: 0.0913 - val_loss: 7.5923 - val_accuracy: 0.0830 - lr: 1.0000e-06\n",
      "Epoch 8/35\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 7.1656 - accuracy: 0.0916 - val_loss: 7.5620 - val_accuracy: 0.0835 - lr: 1.0000e-06\n",
      "Epoch 9/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.1361 - accuracy: 0.0916 - val_loss: 7.6295 - val_accuracy: 0.0833 - lr: 1.0000e-06\n",
      "Epoch 10/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 7.1216 - accuracy: 0.0909 - val_loss: 7.5763 - val_accuracy: 0.0785 - lr: 1.0000e-06\n",
      "Epoch 11/35\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 7.1427 - accuracy: 0.0915 - val_loss: 7.5298 - val_accuracy: 0.0808 - lr: 1.0000e-06\n",
      "Epoch 12/35\n",
      "2813/2813 [==============================] - 455s 162ms/step - loss: 7.1492 - accuracy: 0.0915 - val_loss: 7.5944 - val_accuracy: 0.0837 - lr: 1.0000e-06\n",
      "Epoch 13/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.1411 - accuracy: 0.0901 - val_loss: 7.5532 - val_accuracy: 0.0796 - lr: 1.0000e-06\n",
      "Epoch 14/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 7.1441 - accuracy: 0.0913 - val_loss: 7.5429 - val_accuracy: 0.0795 - lr: 1.0000e-06\n",
      "Epoch 15/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.1230 - accuracy: 0.0916 - val_loss: 7.5441 - val_accuracy: 0.0822 - lr: 1.0000e-06\n",
      "Epoch 16/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.1332 - accuracy: 0.0918 - val_loss: 7.4976 - val_accuracy: 0.0815 - lr: 1.0000e-06\n",
      "Epoch 17/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.1331 - accuracy: 0.0906 - val_loss: 7.6251 - val_accuracy: 0.0802 - lr: 1.0000e-06\n",
      "Epoch 18/35\n",
      "2813/2813 [==============================] - 436s 155ms/step - loss: 7.1223 - accuracy: 0.0923 - val_loss: 7.5415 - val_accuracy: 0.0783 - lr: 1.0000e-06\n",
      "Epoch 19/35\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 7.1308 - accuracy: 0.0915 - val_loss: 7.5435 - val_accuracy: 0.0825 - lr: 1.0000e-06\n",
      "Epoch 20/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.1297 - accuracy: 0.0907 - val_loss: 7.5267 - val_accuracy: 0.0792 - lr: 1.0000e-06\n",
      "Epoch 21/35\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 7.1269 - accuracy: 0.0917\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.1269 - accuracy: 0.0917 - val_loss: 7.5601 - val_accuracy: 0.0837 - lr: 1.0000e-06\n",
      "Epoch 22/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 7.0674 - accuracy: 0.0916 - val_loss: 7.5131 - val_accuracy: 0.0830 - lr: 1.0000e-07\n",
      "Epoch 23/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.0587 - accuracy: 0.0935 - val_loss: 7.4921 - val_accuracy: 0.0835 - lr: 1.0000e-07\n",
      "Epoch 24/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0728 - accuracy: 0.0919 - val_loss: 7.5467 - val_accuracy: 0.0845 - lr: 1.0000e-07\n",
      "Epoch 25/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0539 - accuracy: 0.0929 - val_loss: 7.4905 - val_accuracy: 0.0797 - lr: 1.0000e-07\n",
      "Epoch 26/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0721 - accuracy: 0.0924 - val_loss: 7.4896 - val_accuracy: 0.0828 - lr: 1.0000e-07\n",
      "Epoch 27/35\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 7.0539 - accuracy: 0.0945 - val_loss: 7.4699 - val_accuracy: 0.0829 - lr: 1.0000e-07\n",
      "Epoch 28/35\n",
      "2813/2813 [==============================] - 438s 156ms/step - loss: 7.0700 - accuracy: 0.0923 - val_loss: 7.4637 - val_accuracy: 0.0819 - lr: 1.0000e-07\n",
      "Epoch 29/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.0683 - accuracy: 0.0912 - val_loss: 7.4559 - val_accuracy: 0.0823 - lr: 1.0000e-07\n",
      "Epoch 30/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0513 - accuracy: 0.0925 - val_loss: 7.4994 - val_accuracy: 0.0839 - lr: 1.0000e-07\n",
      "Epoch 31/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.0679 - accuracy: 0.0928 - val_loss: 7.4733 - val_accuracy: 0.0825 - lr: 1.0000e-07\n",
      "Epoch 32/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.0616 - accuracy: 0.0919 - val_loss: 7.6038 - val_accuracy: 0.0787 - lr: 1.0000e-07\n",
      "Epoch 33/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0631 - accuracy: 0.0920 - val_loss: 7.5054 - val_accuracy: 0.0823 - lr: 1.0000e-07\n",
      "Epoch 34/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 7.0516 - accuracy: 0.0924 - val_loss: 7.4084 - val_accuracy: 0.0840 - lr: 1.0000e-07\n",
      "Epoch 35/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 7.0535 - accuracy: 0.0924 - val_loss: 7.4731 - val_accuracy: 0.0844 - lr: 1.0000e-07\n",
      "Saving model to: resnet_101_35.h5\n",
      "Evaluating model: resnet_101\n",
      "312/782 [==========>...................] - ETA: 39s - loss: 8.8034 - accuracy: 0.0968WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 26s 33ms/step - loss: 8.8045 - accuracy: 0.0966\n",
      "{'loss': 8.8045072555542, 'accuracy': 0.0966000035405159}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet101V2_model,\"resnet_101_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e4b08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: inception_v\n",
      "Epoch 1/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 28.1324 - accuracy: 0.0259 - val_loss: 27.1632 - val_accuracy: 0.0290 - lr: 0.0010\n",
      "Epoch 2/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 27.9710 - accuracy: 0.0270 - val_loss: 28.2413 - val_accuracy: 0.0244 - lr: 0.0010\n",
      "Epoch 3/35\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 28.1690 - accuracy: 0.0263 - val_loss: 29.4570 - val_accuracy: 0.0227 - lr: 0.0010\n",
      "Epoch 4/35\n",
      "2813/2813 [==============================] - 454s 161ms/step - loss: 28.0276 - accuracy: 0.0266 - val_loss: 29.6164 - val_accuracy: 0.0276 - lr: 0.0010\n",
      "Epoch 5/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 28.1346 - accuracy: 0.0270 - val_loss: 25.9030 - val_accuracy: 0.0286 - lr: 0.0010\n",
      "Epoch 6/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 28.1860 - accuracy: 0.0275 - val_loss: 27.8177 - val_accuracy: 0.0249 - lr: 0.0010\n",
      "Epoch 7/35\n",
      "2813/2813 [==============================] - 426s 151ms/step - loss: 28.0688 - accuracy: 0.0270 - val_loss: 26.0869 - val_accuracy: 0.0272 - lr: 0.0010\n",
      "Epoch 8/35\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 28.2159 - accuracy: 0.0273 - val_loss: 29.2090 - val_accuracy: 0.0268 - lr: 0.0010\n",
      "Epoch 9/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 28.3478 - accuracy: 0.0279 - val_loss: 29.0590 - val_accuracy: 0.0204 - lr: 0.0010\n",
      "Epoch 10/35\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 28.2075 - accuracy: 0.0274\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 28.2075 - accuracy: 0.0274 - val_loss: 27.4946 - val_accuracy: 0.0250 - lr: 0.0010\n",
      "Epoch 11/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 9.7031 - accuracy: 0.0542 - val_loss: 8.8980 - val_accuracy: 0.0469 - lr: 1.0000e-04\n",
      "Epoch 12/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 8.2212 - accuracy: 0.0568 - val_loss: 8.3138 - val_accuracy: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 13/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 7.8331 - accuracy: 0.0550 - val_loss: 8.0618 - val_accuracy: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 14/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 7.5252 - accuracy: 0.0569 - val_loss: 7.9885 - val_accuracy: 0.0501 - lr: 1.0000e-04\n",
      "Epoch 15/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 7.3110 - accuracy: 0.0567 - val_loss: 7.7886 - val_accuracy: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 16/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 7.1634 - accuracy: 0.0566 - val_loss: 7.3832 - val_accuracy: 0.0460 - lr: 1.0000e-04\n",
      "Epoch 17/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 7.0458 - accuracy: 0.0549 - val_loss: 7.2397 - val_accuracy: 0.0497 - lr: 1.0000e-04\n",
      "Epoch 18/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 6.9439 - accuracy: 0.0556 - val_loss: 7.1846 - val_accuracy: 0.0494 - lr: 1.0000e-04\n",
      "Epoch 19/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.8264 - accuracy: 0.0563 - val_loss: 7.3489 - val_accuracy: 0.0442 - lr: 1.0000e-04\n",
      "Epoch 20/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.7940 - accuracy: 0.0541 - val_loss: 7.2601 - val_accuracy: 0.0465 - lr: 1.0000e-04\n",
      "Epoch 21/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 6.6928 - accuracy: 0.0558 - val_loss: 7.1764 - val_accuracy: 0.0433 - lr: 1.0000e-04\n",
      "Epoch 22/35\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 6.6292 - accuracy: 0.0542 - val_loss: 7.0175 - val_accuracy: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 23/35\n",
      "2813/2813 [==============================] - 425s 151ms/step - loss: 6.5592 - accuracy: 0.0549 - val_loss: 6.7803 - val_accuracy: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 24/35\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 6.5381 - accuracy: 0.0560 - val_loss: 6.8659 - val_accuracy: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 25/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.4965 - accuracy: 0.0551 - val_loss: 6.8798 - val_accuracy: 0.0448 - lr: 1.0000e-04\n",
      "Epoch 26/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.4277 - accuracy: 0.0549 - val_loss: 6.8924 - val_accuracy: 0.0405 - lr: 1.0000e-04\n",
      "Epoch 27/35\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 6.4156 - accuracy: 0.0551 - val_loss: 6.6473 - val_accuracy: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 28/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.3793 - accuracy: 0.0547 - val_loss: 6.7390 - val_accuracy: 0.0441 - lr: 1.0000e-04\n",
      "Epoch 29/35\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 6.3532 - accuracy: 0.0548 - val_loss: 6.4516 - val_accuracy: 0.0478 - lr: 1.0000e-04\n",
      "Epoch 30/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.3235 - accuracy: 0.0534 - val_loss: 6.5795 - val_accuracy: 0.0472 - lr: 1.0000e-04\n",
      "Epoch 31/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.2825 - accuracy: 0.0553 - val_loss: 6.8128 - val_accuracy: 0.0466 - lr: 1.0000e-04\n",
      "Epoch 32/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.2611 - accuracy: 0.0534 - val_loss: 6.4205 - val_accuracy: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 33/35\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 6.2559 - accuracy: 0.0539 - val_loss: 6.5432 - val_accuracy: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 34/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.2281 - accuracy: 0.0524 - val_loss: 6.2396 - val_accuracy: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 35/35\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.2082 - accuracy: 0.0548 - val_loss: 6.5407 - val_accuracy: 0.0430 - lr: 1.0000e-04\n",
      "Saving model to: inception_v335.h5\n",
      "Evaluating model: inception_v\n",
      "313/782 [===========>..................] - ETA: 17s - loss: 6.7325 - accuracy: 0.0558WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 6.7325 - accuracy: 0.0558\n",
      "{'loss': 6.732499122619629, 'accuracy': 0.055799998342990875}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(inceptionv3_model,\"inception_v3\",n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87462d14",
   "metadata": {},
   "source": [
    "Finetuning is taking much longer than I hoped. 100 epochs is beyond reasonable execution time. I'll do 20 more epochs on each model to bring the total number of epochs trained to 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a639308-5277-48e8-93e7-b97572fe237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_16\n",
      "Epoch 1/20\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 47.1535 - accuracy: 0.3918 - val_loss: 69.8604 - val_accuracy: 0.2949 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 47.0564 - accuracy: 0.3903 - val_loss: 67.6218 - val_accuracy: 0.2991 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 46.2903 - accuracy: 0.3935 - val_loss: 67.4001 - val_accuracy: 0.2954 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 45.9570 - accuracy: 0.3970 - val_loss: 67.8367 - val_accuracy: 0.3019 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 45.5338 - accuracy: 0.3931 - val_loss: 66.7815 - val_accuracy: 0.3010 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 45.2008 - accuracy: 0.3964 - val_loss: 65.9101 - val_accuracy: 0.3025 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 44.6796 - accuracy: 0.3942 - val_loss: 66.2908 - val_accuracy: 0.3004 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 44.1128 - accuracy: 0.3962 - val_loss: 65.5878 - val_accuracy: 0.3018 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 44.0814 - accuracy: 0.3959 - val_loss: 64.6109 - val_accuracy: 0.3019 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2813/2813 [==============================] - 441s 157ms/step - loss: 43.6170 - accuracy: 0.3945 - val_loss: 64.3379 - val_accuracy: 0.3052 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 43.3823 - accuracy: 0.3956 - val_loss: 63.1585 - val_accuracy: 0.3030 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 43.0245 - accuracy: 0.3954 - val_loss: 63.0067 - val_accuracy: 0.2963 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 42.4333 - accuracy: 0.3992 - val_loss: 64.2245 - val_accuracy: 0.2955 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 42.0798 - accuracy: 0.3987 - val_loss: 63.6217 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 41.9481 - accuracy: 0.3962 - val_loss: 62.8842 - val_accuracy: 0.3008 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 41.3995 - accuracy: 0.3994 - val_loss: 62.9037 - val_accuracy: 0.2954 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 41.1160 - accuracy: 0.4001 - val_loss: 62.4354 - val_accuracy: 0.2990 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "2813/2813 [==============================] - 426s 152ms/step - loss: 41.1233 - accuracy: 0.3981 - val_loss: 61.2537 - val_accuracy: 0.3029 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 40.6939 - accuracy: 0.4002 - val_loss: 61.7254 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 40.5370 - accuracy: 0.3972 - val_loss: 61.1910 - val_accuracy: 0.3029 - lr: 1.0000e-04\n",
      "Saving model to: vgg_16_20.h5\n",
      "Evaluating model: vgg_16\n",
      "312/782 [==========>...................] - ETA: 28s - loss: 71.4947 - accuracy: 0.3122WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 71.5278 - accuracy: 0.3120\n",
      "{'loss': 71.52781677246094, 'accuracy': 0.31200000643730164}\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "train_test_model(vgg16_model,\"vgg_16_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944403c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: vgg_19\n",
      "Epoch 1/20\n",
      "2813/2813 [==============================] - 428s 152ms/step - loss: 41.8585 - accuracy: 0.3839 - val_loss: 59.8364 - val_accuracy: 0.2986 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 41.7384 - accuracy: 0.3844 - val_loss: 59.8510 - val_accuracy: 0.2975 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 41.1127 - accuracy: 0.3856 - val_loss: 60.0446 - val_accuracy: 0.2869 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 40.9588 - accuracy: 0.3827 - val_loss: 59.7701 - val_accuracy: 0.2897 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2813/2813 [==============================] - 427s 152ms/step - loss: 40.4126 - accuracy: 0.3855 - val_loss: 58.6765 - val_accuracy: 0.2968 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 40.3058 - accuracy: 0.3854 - val_loss: 58.5677 - val_accuracy: 0.2916 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 39.7687 - accuracy: 0.3842 - val_loss: 57.3329 - val_accuracy: 0.2982 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 39.4593 - accuracy: 0.3876 - val_loss: 57.1796 - val_accuracy: 0.2969 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 39.1410 - accuracy: 0.3868 - val_loss: 56.8396 - val_accuracy: 0.2897 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 38.6294 - accuracy: 0.3887 - val_loss: 57.6047 - val_accuracy: 0.2918 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2813/2813 [==============================] - 429s 152ms/step - loss: 38.8733 - accuracy: 0.3833 - val_loss: 56.2263 - val_accuracy: 0.2971 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 38.2159 - accuracy: 0.3890 - val_loss: 56.1451 - val_accuracy: 0.2931 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 38.0197 - accuracy: 0.3846 - val_loss: 55.4490 - val_accuracy: 0.2961 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 37.6489 - accuracy: 0.3894 - val_loss: 54.8927 - val_accuracy: 0.2972 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 37.3135 - accuracy: 0.3885 - val_loss: 54.5655 - val_accuracy: 0.2940 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 37.2398 - accuracy: 0.3878 - val_loss: 54.6041 - val_accuracy: 0.2930 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 36.9345 - accuracy: 0.3870 - val_loss: 54.3644 - val_accuracy: 0.2911 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 36.6847 - accuracy: 0.3890 - val_loss: 54.6057 - val_accuracy: 0.2880 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 36.1747 - accuracy: 0.3874 - val_loss: 54.2972 - val_accuracy: 0.2880 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 36.0735 - accuracy: 0.3878 - val_loss: 54.2604 - val_accuracy: 0.2914 - lr: 1.0000e-04\n",
      "Saving model to: vgg_19_20.h5\n",
      "Evaluating model: vgg_19\n",
      "312/782 [==========>...................] - ETA: 33s - loss: 66.8065 - accuracy: 0.3054WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 66.7993 - accuracy: 0.3054\n",
      "{'loss': 66.79926300048828, 'accuracy': 0.305400013923645}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(vgg19_model,\"vgg_19_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f30a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_50\n",
      "Epoch 1/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 9.9707 - accuracy: 0.1104 - val_loss: 10.6205 - val_accuracy: 0.0965 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 9.8960 - accuracy: 0.1108 - val_loss: 10.5721 - val_accuracy: 0.0929 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2813/2813 [==============================] - 441s 157ms/step - loss: 9.8099 - accuracy: 0.1129 - val_loss: 10.2911 - val_accuracy: 0.0905 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 9.7888 - accuracy: 0.1098 - val_loss: 11.0859 - val_accuracy: 0.0885 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 9.7174 - accuracy: 0.1114 - val_loss: 10.3458 - val_accuracy: 0.0916 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 9.6192 - accuracy: 0.1107 - val_loss: 10.9007 - val_accuracy: 0.0814 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 9.6628 - accuracy: 0.1098 - val_loss: 9.8737 - val_accuracy: 0.0983 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 9.5428 - accuracy: 0.1094 - val_loss: 10.2167 - val_accuracy: 0.0953 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 9.5390 - accuracy: 0.1095 - val_loss: 9.9377 - val_accuracy: 0.1015 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2813/2813 [==============================] - 432s 153ms/step - loss: 9.4683 - accuracy: 0.1092 - val_loss: 10.4879 - val_accuracy: 0.0947 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2813/2813 [==============================] - 429s 153ms/step - loss: 9.4209 - accuracy: 0.1100 - val_loss: 10.3398 - val_accuracy: 0.0917 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 9.3767 - accuracy: 0.1104\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 9.3767 - accuracy: 0.1104 - val_loss: 10.3651 - val_accuracy: 0.0933 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.1266 - accuracy: 0.1549 - val_loss: 6.7297 - val_accuracy: 0.1282 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.0041 - accuracy: 0.1554 - val_loss: 6.7774 - val_accuracy: 0.1246 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 5.9779 - accuracy: 0.1541 - val_loss: 6.7112 - val_accuracy: 0.1279 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "2813/2813 [==============================] - 436s 155ms/step - loss: 5.9685 - accuracy: 0.1535 - val_loss: 6.6766 - val_accuracy: 0.1274 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 5.9438 - accuracy: 0.1546 - val_loss: 6.6656 - val_accuracy: 0.1275 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "2813/2813 [==============================] - 443s 158ms/step - loss: 5.9400 - accuracy: 0.1541 - val_loss: 6.6490 - val_accuracy: 0.1285 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 5.9160 - accuracy: 0.1556 - val_loss: 6.6936 - val_accuracy: 0.1253 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "2813/2813 [==============================] - 447s 159ms/step - loss: 5.9262 - accuracy: 0.1532 - val_loss: 6.6440 - val_accuracy: 0.1283 - lr: 1.0000e-05\n",
      "Saving model to: resnet_50_20.h5\n",
      "Evaluating model: resnet_50\n",
      "313/782 [===========>..................] - ETA: 22s - loss: 8.0476 - accuracy: 0.1431WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 8.0476 - accuracy: 0.1431\n",
      "{'loss': 8.047593116760254, 'accuracy': 0.14309999346733093}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet50v2_model,\"resnet_50_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf2fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: resnet_101\n",
      "Epoch 1/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0840 - accuracy: 0.0914 - val_loss: 7.4825 - val_accuracy: 0.0809 - lr: 1.0000e-07\n",
      "Epoch 2/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 7.0416 - accuracy: 0.0930 - val_loss: 7.5009 - val_accuracy: 0.0842 - lr: 1.0000e-07\n",
      "Epoch 3/20\n",
      "2813/2813 [==============================] - 469s 167ms/step - loss: 7.0659 - accuracy: 0.0927 - val_loss: 7.4887 - val_accuracy: 0.0851 - lr: 1.0000e-07\n",
      "Epoch 4/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 7.0593 - accuracy: 0.0910 - val_loss: 7.4320 - val_accuracy: 0.0769 - lr: 1.0000e-07\n",
      "Epoch 5/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 7.0739 - accuracy: 0.0921 - val_loss: 7.4820 - val_accuracy: 0.0795 - lr: 1.0000e-07\n",
      "Epoch 6/20\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 7.0293 - accuracy: 0.0930 - val_loss: 7.5482 - val_accuracy: 0.0841 - lr: 1.0000e-07\n",
      "Epoch 7/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0491 - accuracy: 0.0921 - val_loss: 7.4828 - val_accuracy: 0.0814 - lr: 1.0000e-07\n",
      "Epoch 8/20\n",
      "2813/2813 [==============================] - 449s 160ms/step - loss: 7.0643 - accuracy: 0.0914 - val_loss: 7.4863 - val_accuracy: 0.0821 - lr: 1.0000e-07\n",
      "Epoch 9/20\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 7.0564 - accuracy: 0.0940\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 7.0564 - accuracy: 0.0940 - val_loss: 7.5232 - val_accuracy: 0.0824 - lr: 1.0000e-07\n",
      "Epoch 10/20\n",
      "2813/2813 [==============================] - 442s 157ms/step - loss: 7.0636 - accuracy: 0.0926 - val_loss: 7.4596 - val_accuracy: 0.0843 - lr: 1.0000e-08\n",
      "Epoch 11/20\n",
      "2813/2813 [==============================] - 438s 156ms/step - loss: 7.0635 - accuracy: 0.0924 - val_loss: 7.5243 - val_accuracy: 0.0789 - lr: 1.0000e-08\n",
      "Epoch 12/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0523 - accuracy: 0.0923 - val_loss: 7.5110 - val_accuracy: 0.0810 - lr: 1.0000e-08\n",
      "Epoch 13/20\n",
      "2813/2813 [==============================] - 435s 154ms/step - loss: 7.0450 - accuracy: 0.0919 - val_loss: 7.5287 - val_accuracy: 0.0790 - lr: 1.0000e-08\n",
      "Epoch 14/20\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 7.0420 - accuracy: 0.0925\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 7.0420 - accuracy: 0.0925 - val_loss: 7.5598 - val_accuracy: 0.0800 - lr: 1.0000e-08\n",
      "Epoch 15/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0545 - accuracy: 0.0919 - val_loss: 7.5206 - val_accuracy: 0.0839 - lr: 1.0000e-09\n",
      "Epoch 16/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 7.0682 - accuracy: 0.0918 - val_loss: 7.4743 - val_accuracy: 0.0786 - lr: 1.0000e-09\n",
      "Epoch 17/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 7.0629 - accuracy: 0.0917 - val_loss: 7.5603 - val_accuracy: 0.0761 - lr: 1.0000e-09\n",
      "Epoch 18/20\n",
      "2813/2813 [==============================] - 436s 155ms/step - loss: 7.0351 - accuracy: 0.0914 - val_loss: 7.4902 - val_accuracy: 0.0827 - lr: 1.0000e-09\n",
      "Epoch 19/20\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 7.0696 - accuracy: 0.0922\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0696 - accuracy: 0.0922 - val_loss: 7.5014 - val_accuracy: 0.0812 - lr: 1.0000e-09\n",
      "Epoch 20/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 7.0467 - accuracy: 0.0932 - val_loss: 7.5024 - val_accuracy: 0.0819 - lr: 1.0000e-10\n",
      "Saving model to: resnet_101_20.h5\n",
      "Evaluating model: resnet_101\n",
      "313/782 [===========>..................] - ETA: 39s - loss: 8.7913 - accuracy: 0.0974WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 27s 34ms/step - loss: 8.7913 - accuracy: 0.0974\n",
      "{'loss': 8.791340827941895, 'accuracy': 0.09740000218153}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(resnet101V2_model,\"resnet_101_\",n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03d085be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: inception_v\n",
      "Epoch 1/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 6.1865 - accuracy: 0.0541 - val_loss: 6.5046 - val_accuracy: 0.0470 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.1643 - accuracy: 0.0544 - val_loss: 6.3543 - val_accuracy: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 6.1505 - accuracy: 0.0532 - val_loss: 6.2087 - val_accuracy: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 6.1391 - accuracy: 0.0540 - val_loss: 6.4592 - val_accuracy: 0.0460 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 6.1394 - accuracy: 0.0535 - val_loss: 6.2819 - val_accuracy: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 6.1117 - accuracy: 0.0539 - val_loss: 6.3007 - val_accuracy: 0.0469 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.0945 - accuracy: 0.0540 - val_loss: 6.3511 - val_accuracy: 0.0446 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.1082 - accuracy: 0.0527 - val_loss: 6.1706 - val_accuracy: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.0768 - accuracy: 0.0532 - val_loss: 6.4610 - val_accuracy: 0.0470 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 6.0719 - accuracy: 0.0529 - val_loss: 6.2828 - val_accuracy: 0.0459 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2813/2813 [==============================] - 430s 153ms/step - loss: 6.0631 - accuracy: 0.0543 - val_loss: 6.3726 - val_accuracy: 0.0444 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 6.0595 - accuracy: 0.0544 - val_loss: 6.1493 - val_accuracy: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 6.0651 - accuracy: 0.0529 - val_loss: 6.0968 - val_accuracy: 0.0440 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "2813/2813 [==============================] - 432s 153ms/step - loss: 6.0327 - accuracy: 0.0529 - val_loss: 6.3422 - val_accuracy: 0.0461 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 6.0359 - accuracy: 0.0529 - val_loss: 6.2755 - val_accuracy: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "2813/2813 [==============================] - 432s 154ms/step - loss: 6.0242 - accuracy: 0.0533 - val_loss: 6.3022 - val_accuracy: 0.0471 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "2813/2813 [==============================] - 434s 154ms/step - loss: 6.0207 - accuracy: 0.0532 - val_loss: 6.2186 - val_accuracy: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 6.0002 - accuracy: 0.0529\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2813/2813 [==============================] - 433s 154ms/step - loss: 6.0002 - accuracy: 0.0529 - val_loss: 6.3639 - val_accuracy: 0.0453 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "2813/2813 [==============================] - 431s 153ms/step - loss: 4.8861 - accuracy: 0.0791 - val_loss: 5.0462 - val_accuracy: 0.0623 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "2813/2813 [==============================] - 466s 166ms/step - loss: 4.8105 - accuracy: 0.0801 - val_loss: 5.0326 - val_accuracy: 0.0688 - lr: 1.0000e-05\n",
      "Saving model to: inception_v320.h5\n",
      "Evaluating model: inception_v\n",
      "313/782 [===========>..................] - ETA: 17s - loss: 4.9651 - accuracy: 0.0855WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 782 batches). You may need to use the repeat() function when building your dataset.\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 4.9651 - accuracy: 0.0855\n",
      "{'loss': 4.965134620666504, 'accuracy': 0.08550000190734863}\n"
     ]
    }
   ],
   "source": [
    "train_test_model(inceptionv3_model,\"inception_v3\",n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72152893-f8a7-4166-9cec-48aa0e4aac53",
   "metadata": {},
   "source": [
    "Here are some summary of the stuctures of the models we just trained to help my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e102d394-fc2d-454a-a61b-d541136d15a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               5017800   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,732,488\n",
      "Trainable params: 5,017,800\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "VGG19\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               5017800   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,042,184\n",
      "Trainable params: 5,017,800\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Resnet50\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 200)          409800      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,974,600\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n",
      "Resnet100\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_8[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block6_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block7_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block7_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block7_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block7_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block7_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block7_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block7_out (Add)         (None, 14, 14, 1024  0           ['conv4_block6_out[0][0]',       \n",
      "                                )                                 'conv4_block7_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block7_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block8_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block8_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block8_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block8_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block8_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block8_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block8_out (Add)         (None, 14, 14, 1024  0           ['conv4_block7_out[0][0]',       \n",
      "                                )                                 'conv4_block8_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block8_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block9_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block9_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block9_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block9_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block9_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block9_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block9_out (Add)         (None, 14, 14, 1024  0           ['conv4_block8_out[0][0]',       \n",
      "                                )                                 'conv4_block9_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block9_out[0][0]']       \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block10_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block10_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block10_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block10_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block10_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block10_out (Add)        (None, 14, 14, 1024  0           ['conv4_block9_out[0][0]',       \n",
      "                                )                                 'conv4_block10_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block10_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block11_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block11_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block11_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block11_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block11_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block11_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block11_out (Add)        (None, 14, 14, 1024  0           ['conv4_block10_out[0][0]',      \n",
      "                                )                                 'conv4_block11_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block11_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block12_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block12_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block12_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block12_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block12_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block12_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block12_out (Add)        (None, 14, 14, 1024  0           ['conv4_block11_out[0][0]',      \n",
      "                                )                                 'conv4_block12_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block12_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block13_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block13_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block13_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block13_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block13_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block13_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block13_out (Add)        (None, 14, 14, 1024  0           ['conv4_block12_out[0][0]',      \n",
      "                                )                                 'conv4_block13_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block13_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block14_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block14_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block14_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block14_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block14_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block14_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block14_out (Add)        (None, 14, 14, 1024  0           ['conv4_block13_out[0][0]',      \n",
      "                                )                                 'conv4_block14_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block14_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block15_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block15_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block15_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block15_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block15_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block15_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block15_out (Add)        (None, 14, 14, 1024  0           ['conv4_block14_out[0][0]',      \n",
      "                                )                                 'conv4_block15_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block15_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block16_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block16_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block16_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block16_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block16_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block16_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block16_out (Add)        (None, 14, 14, 1024  0           ['conv4_block15_out[0][0]',      \n",
      "                                )                                 'conv4_block16_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block16_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block17_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block17_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block17_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block17_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block17_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block17_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block17_out (Add)        (None, 14, 14, 1024  0           ['conv4_block16_out[0][0]',      \n",
      "                                )                                 'conv4_block17_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block17_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block18_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block18_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block18_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block18_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block18_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block18_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block18_out (Add)        (None, 14, 14, 1024  0           ['conv4_block17_out[0][0]',      \n",
      "                                )                                 'conv4_block18_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block18_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block19_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block19_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block19_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block19_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block19_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block19_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block19_out (Add)        (None, 14, 14, 1024  0           ['conv4_block18_out[0][0]',      \n",
      "                                )                                 'conv4_block19_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block19_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block20_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block20_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block20_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block20_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block20_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block20_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block20_out (Add)        (None, 14, 14, 1024  0           ['conv4_block19_out[0][0]',      \n",
      "                                )                                 'conv4_block20_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block20_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block21_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block21_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block21_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block21_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block21_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block21_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block21_out (Add)        (None, 14, 14, 1024  0           ['conv4_block20_out[0][0]',      \n",
      "                                )                                 'conv4_block21_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block21_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block22_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block22_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block22_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block22_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block22_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block22_2_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block22_out (Add)        (None, 14, 14, 1024  0           ['conv4_block21_out[0][0]',      \n",
      "                                )                                 'conv4_block22_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block22_out[0][0]']      \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block23_preact_bn[0][0]']\n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block23_preact_relu[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block23_1_relu[0][0]']   \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 7, 7, 256)    589824      ['conv4_block23_2_pad[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block23_2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['conv4_block23_2_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_2_relu (Activati  (None, 7, 7, 256)   0           ['conv4_block23_2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block22_out[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block23_3_conv (Conv2D)  (None, 7, 7, 1024)   263168      ['conv4_block23_2_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_out (Add)        (None, 7, 7, 1024)   0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv4_block23_3_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block23_out[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 200)          409800      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,036,360\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 42,626,560\n",
      "__________________________________________________________________________________________________\n",
      "InceptionV3\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 200)          409800      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,212,584\n",
      "Trainable params: 409,800\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for analysis propurses\n",
    "print(\"VGG16\")\n",
    "vgg16_model.summary()\n",
    "print(\"VGG19\")\n",
    "vgg19_model.summary()\n",
    "print(\"Resnet50\")\n",
    "resnet50v2_model.summary()\n",
    "print(\"Resnet100\")\n",
    "resnet101V2_model.summary()\n",
    "print(\"InceptionV3\")\n",
    "inceptionv3_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
